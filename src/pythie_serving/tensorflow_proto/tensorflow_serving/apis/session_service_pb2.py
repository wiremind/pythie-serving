# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow_serving/apis/session_service.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from pythie_serving.tensorflow_proto.tensorflow.core.protobuf import config_pb2 as tensorflow_dot_core_dot_protobuf_dot_config__pb2
from pythie_serving.tensorflow_proto.tensorflow.core.protobuf import named_tensor_pb2 as tensorflow_dot_core_dot_protobuf_dot_named__tensor__pb2
from pythie_serving.tensorflow_proto.tensorflow_serving.apis import model_pb2 as tensorflow__serving_dot_apis_dot_model__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n-tensorflow_serving/apis/session_service.proto\x12\x12tensorflow.serving\x1a%tensorflow/core/protobuf/config.proto\x1a+tensorflow/core/protobuf/named_tensor.proto\x1a#tensorflow_serving/apis/model.proto\"\xd8\x01\n\x11SessionRunRequest\x12\x31\n\nmodel_spec\x18\x01 \x01(\x0b\x32\x1d.tensorflow.serving.ModelSpec\x12*\n\x04\x66\x65\x65\x64\x18\x02 \x03(\x0b\x32\x1c.tensorflow.NamedTensorProto\x12\r\n\x05\x66\x65tch\x18\x03 \x03(\t\x12\x0e\n\x06target\x18\x04 \x03(\t\x12\x1c\n\x14tensor_name_is_alias\x18\x06 \x01(\x08\x12\'\n\x07options\x18\x05 \x01(\x0b\x32\x16.tensorflow.RunOptions\"\xa0\x01\n\x12SessionRunResponse\x12\x31\n\nmodel_spec\x18\x03 \x01(\x0b\x32\x1d.tensorflow.serving.ModelSpec\x12,\n\x06tensor\x18\x01 \x03(\x0b\x32\x1c.tensorflow.NamedTensorProto\x12)\n\x08metadata\x18\x02 \x01(\x0b\x32\x17.tensorflow.RunMetadata2m\n\x0eSessionService\x12[\n\nSessionRun\x12%.tensorflow.serving.SessionRunRequest\x1a&.tensorflow.serving.SessionRunResponseB\x03\xf8\x01\x01\x62\x06proto3')



_SESSIONRUNREQUEST = DESCRIPTOR.message_types_by_name['SessionRunRequest']
_SESSIONRUNRESPONSE = DESCRIPTOR.message_types_by_name['SessionRunResponse']
SessionRunRequest = _reflection.GeneratedProtocolMessageType('SessionRunRequest', (_message.Message,), {
  'DESCRIPTOR' : _SESSIONRUNREQUEST,
  '__module__' : 'tensorflow_serving.apis.session_service_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.serving.SessionRunRequest)
  })
_sym_db.RegisterMessage(SessionRunRequest)

SessionRunResponse = _reflection.GeneratedProtocolMessageType('SessionRunResponse', (_message.Message,), {
  'DESCRIPTOR' : _SESSIONRUNRESPONSE,
  '__module__' : 'tensorflow_serving.apis.session_service_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.serving.SessionRunResponse)
  })
_sym_db.RegisterMessage(SessionRunResponse)

_SESSIONSERVICE = DESCRIPTOR.services_by_name['SessionService']
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\370\001\001'
  _SESSIONRUNREQUEST._serialized_start=191
  _SESSIONRUNREQUEST._serialized_end=407
  _SESSIONRUNRESPONSE._serialized_start=410
  _SESSIONRUNRESPONSE._serialized_end=570
  _SESSIONSERVICE._serialized_start=572
  _SESSIONSERVICE._serialized_end=681
# @@protoc_insertion_point(module_scope)
