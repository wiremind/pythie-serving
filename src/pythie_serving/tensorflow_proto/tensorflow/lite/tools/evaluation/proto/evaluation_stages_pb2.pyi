"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import tensorflow.lite.tools.evaluation.proto.preprocessing_steps_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class ProcessSpecification(google.protobuf.message.Message):
    """Defines the functionality executed by an EvaluationStage.

    Next ID: 7
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    IMAGE_PREPROCESSING_PARAMS_FIELD_NUMBER: builtins.int
    TOPK_ACCURACY_EVAL_PARAMS_FIELD_NUMBER: builtins.int
    TFLITE_INFERENCE_PARAMS_FIELD_NUMBER: builtins.int
    IMAGE_CLASSIFICATION_PARAMS_FIELD_NUMBER: builtins.int
    OBJECT_DETECTION_AVERAGE_PRECISION_PARAMS_FIELD_NUMBER: builtins.int
    OBJECT_DETECTION_PARAMS_FIELD_NUMBER: builtins.int
    @property
    def image_preprocessing_params(self) -> global___ImagePreprocessingParams: ...
    @property
    def topk_accuracy_eval_params(self) -> global___TopkAccuracyEvalParams: ...
    @property
    def tflite_inference_params(self) -> global___TfliteInferenceParams: ...
    @property
    def image_classification_params(self) -> global___ImageClassificationParams: ...
    @property
    def object_detection_average_precision_params(self) -> global___ObjectDetectionAveragePrecisionParams: ...
    @property
    def object_detection_params(self) -> global___ObjectDetectionParams: ...
    def __init__(self,
        *,
        image_preprocessing_params: typing.Optional[global___ImagePreprocessingParams] = ...,
        topk_accuracy_eval_params: typing.Optional[global___TopkAccuracyEvalParams] = ...,
        tflite_inference_params: typing.Optional[global___TfliteInferenceParams] = ...,
        image_classification_params: typing.Optional[global___ImageClassificationParams] = ...,
        object_detection_average_precision_params: typing.Optional[global___ObjectDetectionAveragePrecisionParams] = ...,
        object_detection_params: typing.Optional[global___ObjectDetectionParams] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["image_classification_params",b"image_classification_params","image_preprocessing_params",b"image_preprocessing_params","object_detection_average_precision_params",b"object_detection_average_precision_params","object_detection_params",b"object_detection_params","params",b"params","tflite_inference_params",b"tflite_inference_params","topk_accuracy_eval_params",b"topk_accuracy_eval_params"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["image_classification_params",b"image_classification_params","image_preprocessing_params",b"image_preprocessing_params","object_detection_average_precision_params",b"object_detection_average_precision_params","object_detection_params",b"object_detection_params","params",b"params","tflite_inference_params",b"tflite_inference_params","topk_accuracy_eval_params",b"topk_accuracy_eval_params"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["params",b"params"]) -> typing.Optional[typing_extensions.Literal["image_preprocessing_params","topk_accuracy_eval_params","tflite_inference_params","image_classification_params","object_detection_average_precision_params","object_detection_params"]]: ...
global___ProcessSpecification = ProcessSpecification

class LatencyMetrics(google.protobuf.message.Message):
    """Latency numbers in microseconds, based on all EvaluationStage::Run() calls so
    far.

    Next ID: 7
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    LAST_US_FIELD_NUMBER: builtins.int
    MAX_US_FIELD_NUMBER: builtins.int
    MIN_US_FIELD_NUMBER: builtins.int
    SUM_US_FIELD_NUMBER: builtins.int
    AVG_US_FIELD_NUMBER: builtins.int
    STD_DEVIATION_US_FIELD_NUMBER: builtins.int
    last_us: builtins.int
    """Latency for the last Run."""

    max_us: builtins.int
    """Maximum latency observed for any Run."""

    min_us: builtins.int
    """Minimum latency observed for any Run."""

    sum_us: builtins.int
    """Sum of all Run latencies."""

    avg_us: builtins.float
    """Average latency across all Runs."""

    std_deviation_us: builtins.int
    """Standard deviation for latency across all Runs."""

    def __init__(self,
        *,
        last_us: typing.Optional[builtins.int] = ...,
        max_us: typing.Optional[builtins.int] = ...,
        min_us: typing.Optional[builtins.int] = ...,
        sum_us: typing.Optional[builtins.int] = ...,
        avg_us: typing.Optional[builtins.float] = ...,
        std_deviation_us: typing.Optional[builtins.int] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["avg_us",b"avg_us","last_us",b"last_us","max_us",b"max_us","min_us",b"min_us","std_deviation_us",b"std_deviation_us","sum_us",b"sum_us"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["avg_us",b"avg_us","last_us",b"last_us","max_us",b"max_us","min_us",b"min_us","std_deviation_us",b"std_deviation_us","sum_us",b"sum_us"]) -> None: ...
global___LatencyMetrics = LatencyMetrics

class AccuracyMetrics(google.protobuf.message.Message):
    """Statistics for an accuracy value over multiple runs of evaluation.

    Next ID: 5
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    MAX_VALUE_FIELD_NUMBER: builtins.int
    MIN_VALUE_FIELD_NUMBER: builtins.int
    AVG_VALUE_FIELD_NUMBER: builtins.int
    STD_DEVIATION_FIELD_NUMBER: builtins.int
    max_value: builtins.float
    """Maximum value observed for any Run."""

    min_value: builtins.float
    """Minimum value observed for any Run."""

    avg_value: builtins.float
    """Average value across all Runs."""

    std_deviation: builtins.float
    """Standard deviation across all Runs."""

    def __init__(self,
        *,
        max_value: typing.Optional[builtins.float] = ...,
        min_value: typing.Optional[builtins.float] = ...,
        avg_value: typing.Optional[builtins.float] = ...,
        std_deviation: typing.Optional[builtins.float] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["avg_value",b"avg_value","max_value",b"max_value","min_value",b"min_value","std_deviation",b"std_deviation"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["avg_value",b"avg_value","max_value",b"max_value","min_value",b"min_value","std_deviation",b"std_deviation"]) -> None: ...
global___AccuracyMetrics = AccuracyMetrics

class ProcessMetrics(google.protobuf.message.Message):
    """Contains process-specific metrics, which may differ based on what an
    EvaluationStage does.

    Next ID: 8
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    TOTAL_LATENCY_FIELD_NUMBER: builtins.int
    TOPK_ACCURACY_METRICS_FIELD_NUMBER: builtins.int
    TFLITE_INFERENCE_METRICS_FIELD_NUMBER: builtins.int
    IMAGE_CLASSIFICATION_METRICS_FIELD_NUMBER: builtins.int
    INFERENCE_PROFILER_METRICS_FIELD_NUMBER: builtins.int
    OBJECT_DETECTION_AVERAGE_PRECISION_METRICS_FIELD_NUMBER: builtins.int
    OBJECT_DETECTION_METRICS_FIELD_NUMBER: builtins.int
    @property
    def total_latency(self) -> global___LatencyMetrics: ...
    @property
    def topk_accuracy_metrics(self) -> global___TopkAccuracyEvalMetrics: ...
    @property
    def tflite_inference_metrics(self) -> global___TfliteInferenceMetrics: ...
    @property
    def image_classification_metrics(self) -> global___ImageClassificationMetrics: ...
    @property
    def inference_profiler_metrics(self) -> global___InferenceProfilerMetrics: ...
    @property
    def object_detection_average_precision_metrics(self) -> global___ObjectDetectionAveragePrecisionMetrics: ...
    @property
    def object_detection_metrics(self) -> global___ObjectDetectionMetrics: ...
    def __init__(self,
        *,
        total_latency: typing.Optional[global___LatencyMetrics] = ...,
        topk_accuracy_metrics: typing.Optional[global___TopkAccuracyEvalMetrics] = ...,
        tflite_inference_metrics: typing.Optional[global___TfliteInferenceMetrics] = ...,
        image_classification_metrics: typing.Optional[global___ImageClassificationMetrics] = ...,
        inference_profiler_metrics: typing.Optional[global___InferenceProfilerMetrics] = ...,
        object_detection_average_precision_metrics: typing.Optional[global___ObjectDetectionAveragePrecisionMetrics] = ...,
        object_detection_metrics: typing.Optional[global___ObjectDetectionMetrics] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["image_classification_metrics",b"image_classification_metrics","inference_profiler_metrics",b"inference_profiler_metrics","object_detection_average_precision_metrics",b"object_detection_average_precision_metrics","object_detection_metrics",b"object_detection_metrics","stage_metrics",b"stage_metrics","tflite_inference_metrics",b"tflite_inference_metrics","topk_accuracy_metrics",b"topk_accuracy_metrics","total_latency",b"total_latency"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["image_classification_metrics",b"image_classification_metrics","inference_profiler_metrics",b"inference_profiler_metrics","object_detection_average_precision_metrics",b"object_detection_average_precision_metrics","object_detection_metrics",b"object_detection_metrics","stage_metrics",b"stage_metrics","tflite_inference_metrics",b"tflite_inference_metrics","topk_accuracy_metrics",b"topk_accuracy_metrics","total_latency",b"total_latency"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["stage_metrics",b"stage_metrics"]) -> typing.Optional[typing_extensions.Literal["topk_accuracy_metrics","tflite_inference_metrics","image_classification_metrics","inference_profiler_metrics","object_detection_average_precision_metrics","object_detection_metrics"]]: ...
global___ProcessMetrics = ProcessMetrics

class ImagePreprocessingParams(google.protobuf.message.Message):
    """Parameters that define how images are preprocessed.

    Next ID: 3
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    STEPS_FIELD_NUMBER: builtins.int
    OUTPUT_TYPE_FIELD_NUMBER: builtins.int
    @property
    def steps(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[tensorflow.lite.tools.evaluation.proto.preprocessing_steps_pb2.ImagePreprocessingStepParams]:
        """Required."""
        pass
    output_type: builtins.int
    """Same as tflite::TfLiteType."""

    def __init__(self,
        *,
        steps: typing.Optional[typing.Iterable[tensorflow.lite.tools.evaluation.proto.preprocessing_steps_pb2.ImagePreprocessingStepParams]] = ...,
        output_type: typing.Optional[builtins.int] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["output_type",b"output_type"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["output_type",b"output_type","steps",b"steps"]) -> None: ...
global___ImagePreprocessingParams = ImagePreprocessingParams

class TfliteInferenceParams(google.protobuf.message.Message):
    """Parameters that control TFLite inference.

    Next ID: 5
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    class _Delegate:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _DelegateEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[TfliteInferenceParams._Delegate.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        NONE: TfliteInferenceParams._Delegate.ValueType  # 0
        NNAPI: TfliteInferenceParams._Delegate.ValueType  # 1
        GPU: TfliteInferenceParams._Delegate.ValueType  # 2
        HEXAGON: TfliteInferenceParams._Delegate.ValueType  # 3
        XNNPACK: TfliteInferenceParams._Delegate.ValueType  # 4
    class Delegate(_Delegate, metaclass=_DelegateEnumTypeWrapper):
        pass

    NONE: TfliteInferenceParams.Delegate.ValueType  # 0
    NNAPI: TfliteInferenceParams.Delegate.ValueType  # 1
    GPU: TfliteInferenceParams.Delegate.ValueType  # 2
    HEXAGON: TfliteInferenceParams.Delegate.ValueType  # 3
    XNNPACK: TfliteInferenceParams.Delegate.ValueType  # 4

    MODEL_FILE_PATH_FIELD_NUMBER: builtins.int
    DELEGATE_FIELD_NUMBER: builtins.int
    NUM_THREADS_FIELD_NUMBER: builtins.int
    INVOCATIONS_PER_RUN_FIELD_NUMBER: builtins.int
    model_file_path: typing.Text
    """Required"""

    delegate: global___TfliteInferenceParams.Delegate.ValueType
    num_threads: builtins.int
    """Number of threads available to the TFLite Interpreter."""

    invocations_per_run: builtins.int
    """Defines how many times the TFLite Interpreter is invoked for every input.
    This helps benchmark cases where extensive pre-processing might not be
    required for every input.
    """

    def __init__(self,
        *,
        model_file_path: typing.Optional[typing.Text] = ...,
        delegate: typing.Optional[global___TfliteInferenceParams.Delegate.ValueType] = ...,
        num_threads: typing.Optional[builtins.int] = ...,
        invocations_per_run: typing.Optional[builtins.int] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["delegate",b"delegate","invocations_per_run",b"invocations_per_run","model_file_path",b"model_file_path","num_threads",b"num_threads"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["delegate",b"delegate","invocations_per_run",b"invocations_per_run","model_file_path",b"model_file_path","num_threads",b"num_threads"]) -> None: ...
global___TfliteInferenceParams = TfliteInferenceParams

class TfliteInferenceMetrics(google.protobuf.message.Message):
    """Metrics specific to TFLite inference.

    Next ID: 2
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    NUM_INFERENCES_FIELD_NUMBER: builtins.int
    num_inferences: builtins.int
    """Number of times the interpreter is invoked."""

    def __init__(self,
        *,
        num_inferences: typing.Optional[builtins.int] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["num_inferences",b"num_inferences"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["num_inferences",b"num_inferences"]) -> None: ...
global___TfliteInferenceMetrics = TfliteInferenceMetrics

class TopkAccuracyEvalParams(google.protobuf.message.Message):
    """Parameters that define how top-K accuracy is evaluated.

    Next ID: 2
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    K_FIELD_NUMBER: builtins.int
    k: builtins.int
    """Required."""

    def __init__(self,
        *,
        k: typing.Optional[builtins.int] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["k",b"k"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["k",b"k"]) -> None: ...
global___TopkAccuracyEvalParams = TopkAccuracyEvalParams

class TopkAccuracyEvalMetrics(google.protobuf.message.Message):
    """Metrics from top-K accuracy evaluation.

    Next ID: 2
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    TOPK_ACCURACIES_FIELD_NUMBER: builtins.int
    @property
    def topk_accuracies(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]:
        """A repeated field of size |k| where the ith element denotes the fraction of
        samples for which the correct label was present in the top (i + 1) model
        outputs.
        For example, topk_accuracies(1) will contain the fraction of
        samples for which the model returned the correct label as the top first or
        second output.
        """
        pass
    def __init__(self,
        *,
        topk_accuracies: typing.Optional[typing.Iterable[builtins.float]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["topk_accuracies",b"topk_accuracies"]) -> None: ...
global___TopkAccuracyEvalMetrics = TopkAccuracyEvalMetrics

class ImageClassificationParams(google.protobuf.message.Message):
    """Parameters that define how the Image Classification task is evaluated
    end-to-end.

    Next ID: 3
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    INFERENCE_PARAMS_FIELD_NUMBER: builtins.int
    TOPK_ACCURACY_EVAL_PARAMS_FIELD_NUMBER: builtins.int
    @property
    def inference_params(self) -> global___TfliteInferenceParams:
        """Required.
        TfLite model should have 1 input & 1 output tensor.
        Input shape: {1, image_height, image_width, 3}
        Output shape: {1, num_total_labels}
        """
        pass
    @property
    def topk_accuracy_eval_params(self) -> global___TopkAccuracyEvalParams:
        """Optional.
        If not set, accuracy evaluation is not performed.
        """
        pass
    def __init__(self,
        *,
        inference_params: typing.Optional[global___TfliteInferenceParams] = ...,
        topk_accuracy_eval_params: typing.Optional[global___TopkAccuracyEvalParams] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["inference_params",b"inference_params","topk_accuracy_eval_params",b"topk_accuracy_eval_params"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["inference_params",b"inference_params","topk_accuracy_eval_params",b"topk_accuracy_eval_params"]) -> None: ...
global___ImageClassificationParams = ImageClassificationParams

class ImageClassificationMetrics(google.protobuf.message.Message):
    """Metrics from evaluation of the image classification task.

    Next ID: 5
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    PRE_PROCESSING_LATENCY_FIELD_NUMBER: builtins.int
    INFERENCE_LATENCY_FIELD_NUMBER: builtins.int
    INFERENCE_METRICS_FIELD_NUMBER: builtins.int
    TOPK_ACCURACY_METRICS_FIELD_NUMBER: builtins.int
    @property
    def pre_processing_latency(self) -> global___LatencyMetrics: ...
    @property
    def inference_latency(self) -> global___LatencyMetrics: ...
    @property
    def inference_metrics(self) -> global___TfliteInferenceMetrics: ...
    @property
    def topk_accuracy_metrics(self) -> global___TopkAccuracyEvalMetrics:
        """Not set if topk_accuracy_eval_params was not populated in
        ImageClassificationParams.
        """
        pass
    def __init__(self,
        *,
        pre_processing_latency: typing.Optional[global___LatencyMetrics] = ...,
        inference_latency: typing.Optional[global___LatencyMetrics] = ...,
        inference_metrics: typing.Optional[global___TfliteInferenceMetrics] = ...,
        topk_accuracy_metrics: typing.Optional[global___TopkAccuracyEvalMetrics] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["inference_latency",b"inference_latency","inference_metrics",b"inference_metrics","pre_processing_latency",b"pre_processing_latency","topk_accuracy_metrics",b"topk_accuracy_metrics"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["inference_latency",b"inference_latency","inference_metrics",b"inference_metrics","pre_processing_latency",b"pre_processing_latency","topk_accuracy_metrics",b"topk_accuracy_metrics"]) -> None: ...
global___ImageClassificationMetrics = ImageClassificationMetrics

class InferenceProfilerMetrics(google.protobuf.message.Message):
    """Metrics computed from comparing TFLite execution in two settings:
    1. User-defined TfliteInferenceParams (The 'test' setting)
    2. Default TfliteInferenceParams (The 'reference' setting)

    Next ID: 4
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    REFERENCE_LATENCY_FIELD_NUMBER: builtins.int
    TEST_LATENCY_FIELD_NUMBER: builtins.int
    OUTPUT_ERRORS_FIELD_NUMBER: builtins.int
    @property
    def reference_latency(self) -> global___LatencyMetrics:
        """Latency metrics from Single-thread CPU inference."""
        pass
    @property
    def test_latency(self) -> global___LatencyMetrics:
        """Latency from TfliteInferenceParams under test."""
        pass
    @property
    def output_errors(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___AccuracyMetrics]:
        """For reference & test output vectors {R, T}, the error is computed as:
        Mean([Abs(R[i] - T[i]) for i in num_elements])
        output_errors[v] : statistics for the error value of the vth output vector
          across all Runs.
        """
        pass
    def __init__(self,
        *,
        reference_latency: typing.Optional[global___LatencyMetrics] = ...,
        test_latency: typing.Optional[global___LatencyMetrics] = ...,
        output_errors: typing.Optional[typing.Iterable[global___AccuracyMetrics]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["reference_latency",b"reference_latency","test_latency",b"test_latency"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["output_errors",b"output_errors","reference_latency",b"reference_latency","test_latency",b"test_latency"]) -> None: ...
global___InferenceProfilerMetrics = InferenceProfilerMetrics

class ObjectDetectionResult(google.protobuf.message.Message):
    """Proto containing information about all the objects (predicted or
    ground-truth) contained in an image.

    Next ID: 4
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    class ObjectInstance(google.protobuf.message.Message):
        """One instance of an object detected in an image.
        Next ID: 4
        """
        DESCRIPTOR: google.protobuf.descriptor.Descriptor
        class NormalizedBoundingBox(google.protobuf.message.Message):
            """Defines the bounding box for a detected object.
            Next ID: 5
            """
            DESCRIPTOR: google.protobuf.descriptor.Descriptor
            NORMALIZED_TOP_FIELD_NUMBER: builtins.int
            NORMALIZED_BOTTOM_FIELD_NUMBER: builtins.int
            NORMALIZED_LEFT_FIELD_NUMBER: builtins.int
            NORMALIZED_RIGHT_FIELD_NUMBER: builtins.int
            normalized_top: builtins.float
            """All boundaries defined below are required.
            Each boundary value should be normalized with respect to the image
            dimensions. This helps evaluate detections independent of image size.
            For example, normalized_top = top_boundary / image_height.
            """

            normalized_bottom: builtins.float
            normalized_left: builtins.float
            normalized_right: builtins.float
            def __init__(self,
                *,
                normalized_top: typing.Optional[builtins.float] = ...,
                normalized_bottom: typing.Optional[builtins.float] = ...,
                normalized_left: typing.Optional[builtins.float] = ...,
                normalized_right: typing.Optional[builtins.float] = ...,
                ) -> None: ...
            def HasField(self, field_name: typing_extensions.Literal["normalized_bottom",b"normalized_bottom","normalized_left",b"normalized_left","normalized_right",b"normalized_right","normalized_top",b"normalized_top"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing_extensions.Literal["normalized_bottom",b"normalized_bottom","normalized_left",b"normalized_left","normalized_right",b"normalized_right","normalized_top",b"normalized_top"]) -> None: ...

        CLASS_ID_FIELD_NUMBER: builtins.int
        BOUNDING_BOX_FIELD_NUMBER: builtins.int
        SCORE_FIELD_NUMBER: builtins.int
        class_id: builtins.int
        """Required."""

        @property
        def bounding_box(self) -> global___ObjectDetectionResult.ObjectInstance.NormalizedBoundingBox:
            """Required"""
            pass
        score: builtins.float
        """Value in (0, 1.0] denoting confidence in this prediction.
        Default value of 1.0 for ground-truth data.
        """

        def __init__(self,
            *,
            class_id: typing.Optional[builtins.int] = ...,
            bounding_box: typing.Optional[global___ObjectDetectionResult.ObjectInstance.NormalizedBoundingBox] = ...,
            score: typing.Optional[builtins.float] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["bounding_box",b"bounding_box","class_id",b"class_id","score",b"score"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["bounding_box",b"bounding_box","class_id",b"class_id","score",b"score"]) -> None: ...

    OBJECTS_FIELD_NUMBER: builtins.int
    IMAGE_NAME_FIELD_NUMBER: builtins.int
    IMAGE_ID_FIELD_NUMBER: builtins.int
    @property
    def objects(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ObjectDetectionResult.ObjectInstance]: ...
    image_name: typing.Text
    """Filename of the image."""

    image_id: builtins.int
    """Unique id for the image."""

    def __init__(self,
        *,
        objects: typing.Optional[typing.Iterable[global___ObjectDetectionResult.ObjectInstance]] = ...,
        image_name: typing.Optional[typing.Text] = ...,
        image_id: typing.Optional[builtins.int] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["image_id",b"image_id","image_name",b"image_name"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["image_id",b"image_id","image_name",b"image_name","objects",b"objects"]) -> None: ...
global___ObjectDetectionResult = ObjectDetectionResult

class ObjectDetectionGroundTruth(google.protobuf.message.Message):
    """Proto containing ground-truth ObjectsSets for all images in a COCO validation
    set.

    Next ID: 2
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DETECTION_RESULTS_FIELD_NUMBER: builtins.int
    @property
    def detection_results(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ObjectDetectionResult]: ...
    def __init__(self,
        *,
        detection_results: typing.Optional[typing.Iterable[global___ObjectDetectionResult]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["detection_results",b"detection_results"]) -> None: ...
global___ObjectDetectionGroundTruth = ObjectDetectionGroundTruth

class ObjectDetectionAveragePrecisionParams(google.protobuf.message.Message):
    """Parameters that define how Average Precision is computed for Object Detection
    task.
    Refer for details: http://cocodataset.org/#detection-eval

    Next ID: 4
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    NUM_CLASSES_FIELD_NUMBER: builtins.int
    IOU_THRESHOLDS_FIELD_NUMBER: builtins.int
    NUM_RECALL_POINTS_FIELD_NUMBER: builtins.int
    num_classes: builtins.int
    """Total object classes. The AP value returned for each IoU threshold is an
    average over all classes encountered in predicted/ground truth sets.
    """

    @property
    def iou_thresholds(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]:
        """A predicted box matches a ground truth box if and only if
        IoU between these two are larger than an IoU threshold.
        AP is computed for all relevant {IoU threshold, class} combinations and
        averaged to get mAP.
        If left empty, evaluation is done for all IoU threshods in the range
        0.5:0.05:0.95 (min:increment:max).
        """
        pass
    num_recall_points: builtins.int
    """AP is computed as the average of maximum precision at (1
    + num_recall_points) recall levels. E.g., if num_recall_points is 10,
    recall levels are 0., 0.1, 0.2, ..., 0.9, 1.0.
    Default: 100
    """

    def __init__(self,
        *,
        num_classes: typing.Optional[builtins.int] = ...,
        iou_thresholds: typing.Optional[typing.Iterable[builtins.float]] = ...,
        num_recall_points: typing.Optional[builtins.int] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["num_classes",b"num_classes","num_recall_points",b"num_recall_points"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["iou_thresholds",b"iou_thresholds","num_classes",b"num_classes","num_recall_points",b"num_recall_points"]) -> None: ...
global___ObjectDetectionAveragePrecisionParams = ObjectDetectionAveragePrecisionParams

class ObjectDetectionAveragePrecisionMetrics(google.protobuf.message.Message):
    """Average Precision metrics from Object Detection task.

    Next ID: 3
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    class AveragePrecision(google.protobuf.message.Message):
        """Average Precision value for a particular IoU threshold.
        Next ID: 3
        """
        DESCRIPTOR: google.protobuf.descriptor.Descriptor
        IOU_THRESHOLD_FIELD_NUMBER: builtins.int
        AVERAGE_PRECISION_FIELD_NUMBER: builtins.int
        iou_threshold: builtins.float
        average_precision: builtins.float
        def __init__(self,
            *,
            iou_threshold: typing.Optional[builtins.float] = ...,
            average_precision: typing.Optional[builtins.float] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["average_precision",b"average_precision","iou_threshold",b"iou_threshold"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["average_precision",b"average_precision","iou_threshold",b"iou_threshold"]) -> None: ...

    INDIVIDUAL_AVERAGE_PRECISIONS_FIELD_NUMBER: builtins.int
    OVERALL_MEAN_AVERAGE_PRECISION_FIELD_NUMBER: builtins.int
    @property
    def individual_average_precisions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ObjectDetectionAveragePrecisionMetrics.AveragePrecision]:
        """One entry for each in
        ObjectDetectionAveragePrecisionParams::iou_thresholds, averaged over all
        classes.
        """
        pass
    overall_mean_average_precision: builtins.float
    """Average of Average Precision across all IoU thresholds."""

    def __init__(self,
        *,
        individual_average_precisions: typing.Optional[typing.Iterable[global___ObjectDetectionAveragePrecisionMetrics.AveragePrecision]] = ...,
        overall_mean_average_precision: typing.Optional[builtins.float] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["overall_mean_average_precision",b"overall_mean_average_precision"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["individual_average_precisions",b"individual_average_precisions","overall_mean_average_precision",b"overall_mean_average_precision"]) -> None: ...
global___ObjectDetectionAveragePrecisionMetrics = ObjectDetectionAveragePrecisionMetrics

class ObjectDetectionParams(google.protobuf.message.Message):
    """Parameters that define how the Object Detection task is evaluated
    end-to-end.

    Next ID: 4
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    INFERENCE_PARAMS_FIELD_NUMBER: builtins.int
    CLASS_OFFSET_FIELD_NUMBER: builtins.int
    AP_PARAMS_FIELD_NUMBER: builtins.int
    @property
    def inference_params(self) -> global___TfliteInferenceParams:
        """Required.
        Model's outputs should be same as a TFLite-compatible SSD model.
        Refer:
        https://www.tensorflow.org/lite/models/object_detection/overview#output
        TODO(b/133772912): Generalize support for other types of object detection
        models.
        """
        pass
    class_offset: builtins.int
    """Optional. Used to match ground-truth categories with model output.
    SSD Mobilenet V1 Model trained on COCO assumes class 0 is background class
    in the label file and class labels start from 1 to number_of_classes+1.
    Therefore, default value is set as 1.
    """

    @property
    def ap_params(self) -> global___ObjectDetectionAveragePrecisionParams: ...
    def __init__(self,
        *,
        inference_params: typing.Optional[global___TfliteInferenceParams] = ...,
        class_offset: typing.Optional[builtins.int] = ...,
        ap_params: typing.Optional[global___ObjectDetectionAveragePrecisionParams] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["ap_params",b"ap_params","class_offset",b"class_offset","inference_params",b"inference_params"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["ap_params",b"ap_params","class_offset",b"class_offset","inference_params",b"inference_params"]) -> None: ...
global___ObjectDetectionParams = ObjectDetectionParams

class ObjectDetectionMetrics(google.protobuf.message.Message):
    """Metrics from evaluation of the object detection task.

    Next ID: 5
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    PRE_PROCESSING_LATENCY_FIELD_NUMBER: builtins.int
    INFERENCE_LATENCY_FIELD_NUMBER: builtins.int
    INFERENCE_METRICS_FIELD_NUMBER: builtins.int
    AVERAGE_PRECISION_METRICS_FIELD_NUMBER: builtins.int
    @property
    def pre_processing_latency(self) -> global___LatencyMetrics: ...
    @property
    def inference_latency(self) -> global___LatencyMetrics: ...
    @property
    def inference_metrics(self) -> global___TfliteInferenceMetrics: ...
    @property
    def average_precision_metrics(self) -> global___ObjectDetectionAveragePrecisionMetrics: ...
    def __init__(self,
        *,
        pre_processing_latency: typing.Optional[global___LatencyMetrics] = ...,
        inference_latency: typing.Optional[global___LatencyMetrics] = ...,
        inference_metrics: typing.Optional[global___TfliteInferenceMetrics] = ...,
        average_precision_metrics: typing.Optional[global___ObjectDetectionAveragePrecisionMetrics] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["average_precision_metrics",b"average_precision_metrics","inference_latency",b"inference_latency","inference_metrics",b"inference_metrics","pre_processing_latency",b"pre_processing_latency"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["average_precision_metrics",b"average_precision_metrics","inference_latency",b"inference_latency","inference_metrics",b"inference_metrics","pre_processing_latency",b"pre_processing_latency"]) -> None: ...
global___ObjectDetectionMetrics = ObjectDetectionMetrics
