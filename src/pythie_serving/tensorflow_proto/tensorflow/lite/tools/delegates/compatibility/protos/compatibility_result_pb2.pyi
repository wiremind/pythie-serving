"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
Copyright 2022 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""
import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import sys
import typing

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _CompatibilityFailureType:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _CompatibilityFailureTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_CompatibilityFailureType.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    DCC_UNSUPPORTED_QUANTIZATION_PARAMETERS: _CompatibilityFailureType.ValueType  # 0
    """Quantization scale and/or zero point are not in the supported
    value(s) for the accelerated operation.
    Applied DDC(s): NNAPI
    """
    DCC_INVALID_ARGUMENT: _CompatibilityFailureType.ValueType  # 1
    """Indicates that the caller specified an invalid argument, such as
    incorrect stride values.
    Applied DDC(s): GPU
    """
    DCC_INTERNAL_ERROR: _CompatibilityFailureType.ValueType  # 2
    """Indicates an internal error has occurred and some invariants
    expected by the underlying system have not been satisfied, such as
    expecting different number of input or ouput tensors.
    Applied DDC(s): GPU
    """
    DCC_UNIMPLEMENTED_ERROR: _CompatibilityFailureType.ValueType  # 3
    """Indicates the operation is not implemented or supported in this
    service. In this case, the operation should not be re-attempted.
    Applied DDC(s): GPU
    """
    DCC_OUT_OF_RANGE: _CompatibilityFailureType.ValueType  # 4
    """Indicates the operation was attempted past the valid range, such
    as requesting an index that goes beyond the array size.
    Applied DDC(s): GPU
    """
    DCC_UNSUPPORTED_OPERATOR: _CompatibilityFailureType.ValueType  # 5
    """The operator is not supported by the Delegate.
    Applied DDC(s): NNAPI
    """
    DCC_UNSUPPORTED_VERSION: _CompatibilityFailureType.ValueType  # 6
    """The given operation or operands are not supported on the
    specified runtime feature level. The min supported version is specified in
    the compatibility failure message.
    Applied DDC(s): NNAPI
    """
    DCC_UNSUPPORTED_OPERATOR_VERSION: _CompatibilityFailureType.ValueType  # 7
    """The version of the operator (value of OpSignature.version)
    for the given op is not supported. The max supported version
    is specified in the compatibility failure message.
    For more details on each operator version see
    the GetBuiltinOperatorVersion function in
    third_party/tensorflow/lite/tools/versioning/op_version.cc.
    Applied DDC(s): NNAPI
    """
    DCC_UNSUPPORTED_INPUT_TYPE: _CompatibilityFailureType.ValueType  # 8
    """The given input operand type is not supported for the current
    combination of operator type and runtime feature level.
    Applied DDC(s): NNAPI
    """
    DCC_NOT_RESTRICTED_SCALE_COMPLIANT: _CompatibilityFailureType.ValueType  # 9
    """When using NN API version 1.0 or 1.1, the condition
      input_scale * filter_scale < output_scale
    must be true for quantized versions of the following ops:
    * CONV_2D
    * DEPTHWISE_CONV_2D
    * FULLY_CONNECTED (where filter actually stands for weights)
    The condition is relaxed and no longer required since version 1.2.
    Applied DDC(s): NNAPI
    """
    DCC_UNSUPPORTED_OUTPUT_TYPE: _CompatibilityFailureType.ValueType  # 10
    """The given output operand type is not supported for the current
    combination of operator type and runtime feature level.
    Applied DDC(s): NNAPI
    """
    DCC_UNSUPPORTED_OPERAND_SIZE: _CompatibilityFailureType.ValueType  # 11
    """The size of the operand tensor is too large.
    Applied DDC(s): NNAPI
    """
    DCC_UNSUPPORTED_OPERAND_VALUE: _CompatibilityFailureType.ValueType  # 12
    """The value of one of the operands or of a combination of operands
    is not supported. Details are provided in the compatibility failure
    message.
    Applied DDC(s): NNAPI
    """
    DCC_UNSUPPORTED_HYBRID_OPERATOR: _CompatibilityFailureType.ValueType  # 13
    """The combination of float inputs and quantized weights or filters
    is not supported.
    Applied DDC(s): NNAPI
    """
    DCC_UNSUPPORTED_QUANTIZATION_TYPE: _CompatibilityFailureType.ValueType  # 14
    """The quantization type (for example per-channel quantization) is
    not supported.
    Applied DDC(s): NNAPI
    """
    DCC_MISSING_REQUIRED_OPERAND: _CompatibilityFailureType.ValueType  # 15
    """The accelerated version of operation requires a specific operand
    to be specified.
    Applied DDC(s): NNAPI
    """
    DCC_UNSUPPORTED_OPERAND_RANK: _CompatibilityFailureType.ValueType  # 16
    """The rank of the operand is not supported. Details in the
    compatibility failure message.
    Applied DDC(s): NNAPI
    """
    DCC_INPUT_TENSOR_SHOULD_HAVE_CONSTANT_SHAPE: _CompatibilityFailureType.ValueType  # 17
    """The input tensor cannot be dynamically-sized.
    Applied DDC(s): NNAPI
    """
    DCC_UNSUPPORTED_OPERATOR_VARIANT: _CompatibilityFailureType.ValueType  # 18
    """The operator has a different number of inputs of the one or ones
    that are supported by NNAPI.
    Applied DDC(s): NNAPI
    """
    DCC_NO_ACTIVATION_EXPECTED: _CompatibilityFailureType.ValueType  # 19
    """The accelerated version of the operator cannot specify an
    activation function.
    Applied DDC(s): NNAPI
    """

class CompatibilityFailureType(_CompatibilityFailureType, metaclass=_CompatibilityFailureTypeEnumTypeWrapper): ...

DCC_UNSUPPORTED_QUANTIZATION_PARAMETERS: CompatibilityFailureType.ValueType  # 0
"""Quantization scale and/or zero point are not in the supported
value(s) for the accelerated operation.
Applied DDC(s): NNAPI
"""
DCC_INVALID_ARGUMENT: CompatibilityFailureType.ValueType  # 1
"""Indicates that the caller specified an invalid argument, such as
incorrect stride values.
Applied DDC(s): GPU
"""
DCC_INTERNAL_ERROR: CompatibilityFailureType.ValueType  # 2
"""Indicates an internal error has occurred and some invariants
expected by the underlying system have not been satisfied, such as
expecting different number of input or ouput tensors.
Applied DDC(s): GPU
"""
DCC_UNIMPLEMENTED_ERROR: CompatibilityFailureType.ValueType  # 3
"""Indicates the operation is not implemented or supported in this
service. In this case, the operation should not be re-attempted.
Applied DDC(s): GPU
"""
DCC_OUT_OF_RANGE: CompatibilityFailureType.ValueType  # 4
"""Indicates the operation was attempted past the valid range, such
as requesting an index that goes beyond the array size.
Applied DDC(s): GPU
"""
DCC_UNSUPPORTED_OPERATOR: CompatibilityFailureType.ValueType  # 5
"""The operator is not supported by the Delegate.
Applied DDC(s): NNAPI
"""
DCC_UNSUPPORTED_VERSION: CompatibilityFailureType.ValueType  # 6
"""The given operation or operands are not supported on the
specified runtime feature level. The min supported version is specified in
the compatibility failure message.
Applied DDC(s): NNAPI
"""
DCC_UNSUPPORTED_OPERATOR_VERSION: CompatibilityFailureType.ValueType  # 7
"""The version of the operator (value of OpSignature.version)
for the given op is not supported. The max supported version
is specified in the compatibility failure message.
For more details on each operator version see
the GetBuiltinOperatorVersion function in
third_party/tensorflow/lite/tools/versioning/op_version.cc.
Applied DDC(s): NNAPI
"""
DCC_UNSUPPORTED_INPUT_TYPE: CompatibilityFailureType.ValueType  # 8
"""The given input operand type is not supported for the current
combination of operator type and runtime feature level.
Applied DDC(s): NNAPI
"""
DCC_NOT_RESTRICTED_SCALE_COMPLIANT: CompatibilityFailureType.ValueType  # 9
"""When using NN API version 1.0 or 1.1, the condition
  input_scale * filter_scale < output_scale
must be true for quantized versions of the following ops:
* CONV_2D
* DEPTHWISE_CONV_2D
* FULLY_CONNECTED (where filter actually stands for weights)
The condition is relaxed and no longer required since version 1.2.
Applied DDC(s): NNAPI
"""
DCC_UNSUPPORTED_OUTPUT_TYPE: CompatibilityFailureType.ValueType  # 10
"""The given output operand type is not supported for the current
combination of operator type and runtime feature level.
Applied DDC(s): NNAPI
"""
DCC_UNSUPPORTED_OPERAND_SIZE: CompatibilityFailureType.ValueType  # 11
"""The size of the operand tensor is too large.
Applied DDC(s): NNAPI
"""
DCC_UNSUPPORTED_OPERAND_VALUE: CompatibilityFailureType.ValueType  # 12
"""The value of one of the operands or of a combination of operands
is not supported. Details are provided in the compatibility failure
message.
Applied DDC(s): NNAPI
"""
DCC_UNSUPPORTED_HYBRID_OPERATOR: CompatibilityFailureType.ValueType  # 13
"""The combination of float inputs and quantized weights or filters
is not supported.
Applied DDC(s): NNAPI
"""
DCC_UNSUPPORTED_QUANTIZATION_TYPE: CompatibilityFailureType.ValueType  # 14
"""The quantization type (for example per-channel quantization) is
not supported.
Applied DDC(s): NNAPI
"""
DCC_MISSING_REQUIRED_OPERAND: CompatibilityFailureType.ValueType  # 15
"""The accelerated version of operation requires a specific operand
to be specified.
Applied DDC(s): NNAPI
"""
DCC_UNSUPPORTED_OPERAND_RANK: CompatibilityFailureType.ValueType  # 16
"""The rank of the operand is not supported. Details in the
compatibility failure message.
Applied DDC(s): NNAPI
"""
DCC_INPUT_TENSOR_SHOULD_HAVE_CONSTANT_SHAPE: CompatibilityFailureType.ValueType  # 17
"""The input tensor cannot be dynamically-sized.
Applied DDC(s): NNAPI
"""
DCC_UNSUPPORTED_OPERATOR_VARIANT: CompatibilityFailureType.ValueType  # 18
"""The operator has a different number of inputs of the one or ones
that are supported by NNAPI.
Applied DDC(s): NNAPI
"""
DCC_NO_ACTIVATION_EXPECTED: CompatibilityFailureType.ValueType  # 19
"""The accelerated version of the operator cannot specify an
activation function.
Applied DDC(s): NNAPI
"""
global___CompatibilityFailureType = CompatibilityFailureType

@typing_extensions.final
class CompatibilityFailure(google.protobuf.message.Message):
    """Indicates the type and a human readable text for an error in an operation."""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    FAILURE_TYPE_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    failure_type: global___CompatibilityFailureType.ValueType
    """Type of the errors."""
    description: builtins.str
    """Human readable message explaining the error."""
    def __init__(
        self,
        *,
        failure_type: global___CompatibilityFailureType.ValueType | None = ...,
        description: builtins.str | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["description", b"description", "failure_type", b"failure_type"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["description", b"description", "failure_type", b"failure_type"]) -> None: ...

global___CompatibilityFailure = CompatibilityFailure

@typing_extensions.final
class OpCompatibilityResult(google.protobuf.message.Message):
    """Result for one operation of the given model and stores if the operation
    is supported. If it is supported, validation_failures will not have a value.
    If it is not supported, validation_failures will contain all the errors for
    that operation. Also saves the subgraph index inside the model and the
    operator index inside the subgraph.
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    IS_SUPPORTED_FIELD_NUMBER: builtins.int
    SUBGRAPH_INDEX_IN_MODEL_FIELD_NUMBER: builtins.int
    OPERATOR_INDEX_IN_SUBGRAPH_FIELD_NUMBER: builtins.int
    COMPATIBILITY_FAILURES_FIELD_NUMBER: builtins.int
    is_supported: builtins.bool
    """True if the operation is supported for the required DCC."""
    subgraph_index_in_model: builtins.int
    """Index of the subgraph where this operation is contained."""
    operator_index_in_subgraph: builtins.int
    """Index of the operator inside the subgraph."""
    @property
    def compatibility_failures(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___CompatibilityFailure]:
        """Type of the errors."""
    def __init__(
        self,
        *,
        is_supported: builtins.bool | None = ...,
        subgraph_index_in_model: builtins.int | None = ...,
        operator_index_in_subgraph: builtins.int | None = ...,
        compatibility_failures: collections.abc.Iterable[global___CompatibilityFailure] | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["is_supported", b"is_supported", "operator_index_in_subgraph", b"operator_index_in_subgraph", "subgraph_index_in_model", b"subgraph_index_in_model"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["compatibility_failures", b"compatibility_failures", "is_supported", b"is_supported", "operator_index_in_subgraph", b"operator_index_in_subgraph", "subgraph_index_in_model", b"subgraph_index_in_model"]) -> None: ...

global___OpCompatibilityResult = OpCompatibilityResult

@typing_extensions.final
class CompatibilityResult(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    COMPATIBILITY_RESULTS_FIELD_NUMBER: builtins.int
    @property
    def compatibility_results(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___OpCompatibilityResult]:
        """One result for each operation."""
    def __init__(
        self,
        *,
        compatibility_results: collections.abc.Iterable[global___OpCompatibilityResult] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["compatibility_results", b"compatibility_results"]) -> None: ...

global___CompatibilityResult = CompatibilityResult
