"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _AutoShardPolicy:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _AutoShardPolicyEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_AutoShardPolicy.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    AUTO: _AutoShardPolicy.ValueType  # 0
    """AUTO: Attempts FILE-based sharding, falling back to DATA-based sharding."""

    FILE: _AutoShardPolicy.ValueType  # 1
    """FILE: Shards by input files (i.e. each worker will get a set of files to
    process). When this option is selected, make sure that there is at least as
    many files as workers. If there are fewer input files than workers, a
    runtime error will be raised.
    """

    DATA: _AutoShardPolicy.ValueType  # 2
    """DATA: Shards by elements produced by the dataset. Each worker will process
    the whole dataset and discard the portion that is not for itself. Note that
    for this mode to correctly partitions the dataset elements, the dataset
    needs to produce elements in a deterministic order.
    """

    HINT: _AutoShardPolicy.ValueType  # 3
    """HINT: Looks for the presence of `shard(SHARD_HINT, ...)` which is treated
    as a placeholder to replace with `shard(num_workers, worker_index)`.
    """

    OFF: _AutoShardPolicy.ValueType  # -1
    """OFF: No sharding will be performed."""

class AutoShardPolicy(_AutoShardPolicy, metaclass=_AutoShardPolicyEnumTypeWrapper):
    """Represents the type of auto-sharding we enable."""
    pass

AUTO: AutoShardPolicy.ValueType  # 0
"""AUTO: Attempts FILE-based sharding, falling back to DATA-based sharding."""

FILE: AutoShardPolicy.ValueType  # 1
"""FILE: Shards by input files (i.e. each worker will get a set of files to
process). When this option is selected, make sure that there is at least as
many files as workers. If there are fewer input files than workers, a
runtime error will be raised.
"""

DATA: AutoShardPolicy.ValueType  # 2
"""DATA: Shards by elements produced by the dataset. Each worker will process
the whole dataset and discard the portion that is not for itself. Note that
for this mode to correctly partitions the dataset elements, the dataset
needs to produce elements in a deterministic order.
"""

HINT: AutoShardPolicy.ValueType  # 3
"""HINT: Looks for the presence of `shard(SHARD_HINT, ...)` which is treated
as a placeholder to replace with `shard(num_workers, worker_index)`.
"""

OFF: AutoShardPolicy.ValueType  # -1
"""OFF: No sharding will be performed."""

global___AutoShardPolicy = AutoShardPolicy


class _ExternalStatePolicy:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _ExternalStatePolicyEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ExternalStatePolicy.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    POLICY_WARN: _ExternalStatePolicy.ValueType  # 0
    POLICY_IGNORE: _ExternalStatePolicy.ValueType  # 1
    POLICY_FAIL: _ExternalStatePolicy.ValueType  # 2
class ExternalStatePolicy(_ExternalStatePolicy, metaclass=_ExternalStatePolicyEnumTypeWrapper):
    """Represents how to handle external state during serialization."""
    pass

POLICY_WARN: ExternalStatePolicy.ValueType  # 0
POLICY_IGNORE: ExternalStatePolicy.ValueType  # 1
POLICY_FAIL: ExternalStatePolicy.ValueType  # 2
global___ExternalStatePolicy = ExternalStatePolicy


class DistributeOptions(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    AUTO_SHARD_POLICY_FIELD_NUMBER: builtins.int
    NUM_DEVICES_FIELD_NUMBER: builtins.int
    auto_shard_policy: global___AutoShardPolicy.ValueType
    num_devices: builtins.int
    def __init__(self,
        *,
        auto_shard_policy: global___AutoShardPolicy.ValueType = ...,
        num_devices: builtins.int = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["num_devices",b"num_devices","optional_num_devices",b"optional_num_devices"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["auto_shard_policy",b"auto_shard_policy","num_devices",b"num_devices","optional_num_devices",b"optional_num_devices"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_num_devices",b"optional_num_devices"]) -> typing.Optional[typing_extensions.Literal["num_devices"]]: ...
global___DistributeOptions = DistributeOptions

class OptimizationOptions(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    APPLY_DEFAULT_OPTIMIZATIONS_FIELD_NUMBER: builtins.int
    AUTOTUNE_FIELD_NUMBER: builtins.int
    AUTOTUNE_BUFFERS_FIELD_NUMBER: builtins.int
    AUTOTUNE_CPU_BUDGET_FIELD_NUMBER: builtins.int
    AUTOTUNE_RAM_BUDGET_FIELD_NUMBER: builtins.int
    FILTER_FUSION_FIELD_NUMBER: builtins.int
    MAP_AND_BATCH_FUSION_FIELD_NUMBER: builtins.int
    MAP_AND_FILTER_FUSION_FIELD_NUMBER: builtins.int
    MAP_FUSION_FIELD_NUMBER: builtins.int
    MAP_PARALLELIZATION_FIELD_NUMBER: builtins.int
    NOOP_ELIMINATION_FIELD_NUMBER: builtins.int
    PARALLEL_BATCH_FIELD_NUMBER: builtins.int
    SHUFFLE_AND_REPEAT_FUSION_FIELD_NUMBER: builtins.int
    apply_default_optimizations: builtins.bool
    autotune: builtins.bool
    autotune_buffers: builtins.bool
    autotune_cpu_budget: builtins.int
    autotune_ram_budget: builtins.int
    filter_fusion: builtins.bool
    map_and_batch_fusion: builtins.bool
    map_and_filter_fusion: builtins.bool
    map_fusion: builtins.bool
    map_parallelization: builtins.bool
    noop_elimination: builtins.bool
    parallel_batch: builtins.bool
    shuffle_and_repeat_fusion: builtins.bool
    def __init__(self,
        *,
        apply_default_optimizations: builtins.bool = ...,
        autotune: builtins.bool = ...,
        autotune_buffers: builtins.bool = ...,
        autotune_cpu_budget: builtins.int = ...,
        autotune_ram_budget: builtins.int = ...,
        filter_fusion: builtins.bool = ...,
        map_and_batch_fusion: builtins.bool = ...,
        map_and_filter_fusion: builtins.bool = ...,
        map_fusion: builtins.bool = ...,
        map_parallelization: builtins.bool = ...,
        noop_elimination: builtins.bool = ...,
        parallel_batch: builtins.bool = ...,
        shuffle_and_repeat_fusion: builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["apply_default_optimizations",b"apply_default_optimizations","autotune",b"autotune","autotune_buffers",b"autotune_buffers","autotune_cpu_budget",b"autotune_cpu_budget","autotune_ram_budget",b"autotune_ram_budget","filter_fusion",b"filter_fusion","map_and_batch_fusion",b"map_and_batch_fusion","map_and_filter_fusion",b"map_and_filter_fusion","map_fusion",b"map_fusion","map_parallelization",b"map_parallelization","noop_elimination",b"noop_elimination","optional_apply_default_optimizations",b"optional_apply_default_optimizations","optional_autotune",b"optional_autotune","optional_autotune_buffers",b"optional_autotune_buffers","optional_autotune_cpu_budget",b"optional_autotune_cpu_budget","optional_autotune_ram_budget",b"optional_autotune_ram_budget","optional_filter_fusion",b"optional_filter_fusion","optional_map_and_batch_fusion",b"optional_map_and_batch_fusion","optional_map_and_filter_fusion",b"optional_map_and_filter_fusion","optional_map_fusion",b"optional_map_fusion","optional_map_parallelization",b"optional_map_parallelization","optional_noop_elimination",b"optional_noop_elimination","optional_parallel_batch",b"optional_parallel_batch","optional_shuffle_and_repeat_fusion",b"optional_shuffle_and_repeat_fusion","parallel_batch",b"parallel_batch","shuffle_and_repeat_fusion",b"shuffle_and_repeat_fusion"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["apply_default_optimizations",b"apply_default_optimizations","autotune",b"autotune","autotune_buffers",b"autotune_buffers","autotune_cpu_budget",b"autotune_cpu_budget","autotune_ram_budget",b"autotune_ram_budget","filter_fusion",b"filter_fusion","map_and_batch_fusion",b"map_and_batch_fusion","map_and_filter_fusion",b"map_and_filter_fusion","map_fusion",b"map_fusion","map_parallelization",b"map_parallelization","noop_elimination",b"noop_elimination","optional_apply_default_optimizations",b"optional_apply_default_optimizations","optional_autotune",b"optional_autotune","optional_autotune_buffers",b"optional_autotune_buffers","optional_autotune_cpu_budget",b"optional_autotune_cpu_budget","optional_autotune_ram_budget",b"optional_autotune_ram_budget","optional_filter_fusion",b"optional_filter_fusion","optional_map_and_batch_fusion",b"optional_map_and_batch_fusion","optional_map_and_filter_fusion",b"optional_map_and_filter_fusion","optional_map_fusion",b"optional_map_fusion","optional_map_parallelization",b"optional_map_parallelization","optional_noop_elimination",b"optional_noop_elimination","optional_parallel_batch",b"optional_parallel_batch","optional_shuffle_and_repeat_fusion",b"optional_shuffle_and_repeat_fusion","parallel_batch",b"parallel_batch","shuffle_and_repeat_fusion",b"shuffle_and_repeat_fusion"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_apply_default_optimizations",b"optional_apply_default_optimizations"]) -> typing.Optional[typing_extensions.Literal["apply_default_optimizations"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_autotune",b"optional_autotune"]) -> typing.Optional[typing_extensions.Literal["autotune"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_autotune_buffers",b"optional_autotune_buffers"]) -> typing.Optional[typing_extensions.Literal["autotune_buffers"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_autotune_cpu_budget",b"optional_autotune_cpu_budget"]) -> typing.Optional[typing_extensions.Literal["autotune_cpu_budget"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_autotune_ram_budget",b"optional_autotune_ram_budget"]) -> typing.Optional[typing_extensions.Literal["autotune_ram_budget"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_filter_fusion",b"optional_filter_fusion"]) -> typing.Optional[typing_extensions.Literal["filter_fusion"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_map_and_batch_fusion",b"optional_map_and_batch_fusion"]) -> typing.Optional[typing_extensions.Literal["map_and_batch_fusion"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_map_and_filter_fusion",b"optional_map_and_filter_fusion"]) -> typing.Optional[typing_extensions.Literal["map_and_filter_fusion"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_map_fusion",b"optional_map_fusion"]) -> typing.Optional[typing_extensions.Literal["map_fusion"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_map_parallelization",b"optional_map_parallelization"]) -> typing.Optional[typing_extensions.Literal["map_parallelization"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_noop_elimination",b"optional_noop_elimination"]) -> typing.Optional[typing_extensions.Literal["noop_elimination"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_parallel_batch",b"optional_parallel_batch"]) -> typing.Optional[typing_extensions.Literal["parallel_batch"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_shuffle_and_repeat_fusion",b"optional_shuffle_and_repeat_fusion"]) -> typing.Optional[typing_extensions.Literal["shuffle_and_repeat_fusion"]]: ...
global___OptimizationOptions = OptimizationOptions

class ThreadingOptions(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    MAX_INTRA_OP_PARALLELISM_FIELD_NUMBER: builtins.int
    PRIVATE_THREADPOOL_SIZE_FIELD_NUMBER: builtins.int
    max_intra_op_parallelism: builtins.int
    private_threadpool_size: builtins.int
    def __init__(self,
        *,
        max_intra_op_parallelism: builtins.int = ...,
        private_threadpool_size: builtins.int = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["max_intra_op_parallelism",b"max_intra_op_parallelism","optional_max_intra_op_parallelism",b"optional_max_intra_op_parallelism","optional_private_threadpool_size",b"optional_private_threadpool_size","private_threadpool_size",b"private_threadpool_size"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["max_intra_op_parallelism",b"max_intra_op_parallelism","optional_max_intra_op_parallelism",b"optional_max_intra_op_parallelism","optional_private_threadpool_size",b"optional_private_threadpool_size","private_threadpool_size",b"private_threadpool_size"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_max_intra_op_parallelism",b"optional_max_intra_op_parallelism"]) -> typing.Optional[typing_extensions.Literal["max_intra_op_parallelism"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_private_threadpool_size",b"optional_private_threadpool_size"]) -> typing.Optional[typing_extensions.Literal["private_threadpool_size"]]: ...
global___ThreadingOptions = ThreadingOptions

class Options(google.protobuf.message.Message):
    """Message stored with Dataset objects to control how datasets are processed and
    optimized.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DETERMINISTIC_FIELD_NUMBER: builtins.int
    DISTRIBUTE_OPTIONS_FIELD_NUMBER: builtins.int
    OPTIMIZATION_OPTIONS_FIELD_NUMBER: builtins.int
    SLACK_FIELD_NUMBER: builtins.int
    THREADING_OPTIONS_FIELD_NUMBER: builtins.int
    EXTERNAL_STATE_POLICY_FIELD_NUMBER: builtins.int
    deterministic: builtins.bool
    @property
    def distribute_options(self) -> global___DistributeOptions:
        """The distribution strategy options associated with the dataset."""
        pass
    @property
    def optimization_options(self) -> global___OptimizationOptions:
        """The optimization options associated with the dataset."""
        pass
    slack: builtins.bool
    @property
    def threading_options(self) -> global___ThreadingOptions:
        """The threading options associated with the dataset."""
        pass
    external_state_policy: global___ExternalStatePolicy.ValueType
    def __init__(self,
        *,
        deterministic: builtins.bool = ...,
        distribute_options: typing.Optional[global___DistributeOptions] = ...,
        optimization_options: typing.Optional[global___OptimizationOptions] = ...,
        slack: builtins.bool = ...,
        threading_options: typing.Optional[global___ThreadingOptions] = ...,
        external_state_policy: global___ExternalStatePolicy.ValueType = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["deterministic",b"deterministic","distribute_options",b"distribute_options","external_state_policy",b"external_state_policy","optimization_options",b"optimization_options","optional_deterministic",b"optional_deterministic","optional_external_state_policy",b"optional_external_state_policy","optional_slack",b"optional_slack","slack",b"slack","threading_options",b"threading_options"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["deterministic",b"deterministic","distribute_options",b"distribute_options","external_state_policy",b"external_state_policy","optimization_options",b"optimization_options","optional_deterministic",b"optional_deterministic","optional_external_state_policy",b"optional_external_state_policy","optional_slack",b"optional_slack","slack",b"slack","threading_options",b"threading_options"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_deterministic",b"optional_deterministic"]) -> typing.Optional[typing_extensions.Literal["deterministic"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_external_state_policy",b"optional_external_state_policy"]) -> typing.Optional[typing_extensions.Literal["external_state_policy"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["optional_slack",b"optional_slack"]) -> typing.Optional[typing_extensions.Literal["slack"]]: ...
global___Options = Options
