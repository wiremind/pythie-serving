# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow/core/data/service/common.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import enum_type_wrapper
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from pythie_serving.tensorflow_proto.tensorflow.core.framework import graph_pb2 as tensorflow_dot_core_dot_framework_dot_graph__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n)tensorflow/core/data/service/common.proto\x12\x0ftensorflow.data\x1a%tensorflow/core/framework/graph.proto\"1\n\nDatasetDef\x12#\n\x05graph\x18\x01 \x01(\x0b\x32\x14.tensorflow.GraphDef\"\xb2\x02\n\x07TaskDef\x12\x32\n\x0b\x64\x61taset_def\x18\x01 \x01(\x0b\x32\x1b.tensorflow.data.DatasetDefH\x00\x12\x0e\n\x04path\x18\x02 \x01(\tH\x00\x12\x12\n\ndataset_id\x18\x03 \x01(\x03\x12\x0f\n\x07task_id\x18\x04 \x01(\x03\x12\x0e\n\x06job_id\x18\x05 \x01(\x03\x12\x1b\n\x13num_split_providers\x18\t \x01(\x03\x12\x16\n\x0eworker_address\x18\x08 \x01(\t\x12;\n\x0fprocessing_mode\x18\x06 \x01(\x0e\x32\".tensorflow.data.ProcessingModeDef\x12\x17\n\rnum_consumers\x18\x07 \x01(\x03H\x01\x42\t\n\x07\x64\x61tasetB\x18\n\x16optional_num_consumers\"u\n\x08TaskInfo\x12\x16\n\x0eworker_address\x18\x01 \x01(\t\x12\x18\n\x10transfer_address\x18\x04 \x01(\t\x12\x0f\n\x07task_id\x18\x02 \x01(\x03\x12\x0e\n\x06job_id\x18\x03 \x01(\x03\x12\x16\n\x0estarting_round\x18\x05 \x01(\x03*L\n\x11ProcessingModeDef\x12\x0b\n\x07INVALID\x10\x00\x12\x13\n\x0fPARALLEL_EPOCHS\x10\x01\x12\x15\n\x11\x44ISTRIBUTED_EPOCH\x10\x02\x62\x06proto3')

_PROCESSINGMODEDEF = DESCRIPTOR.enum_types_by_name['ProcessingModeDef']
ProcessingModeDef = enum_type_wrapper.EnumTypeWrapper(_PROCESSINGMODEDEF)
INVALID = 0
PARALLEL_EPOCHS = 1
DISTRIBUTED_EPOCH = 2


_DATASETDEF = DESCRIPTOR.message_types_by_name['DatasetDef']
_TASKDEF = DESCRIPTOR.message_types_by_name['TaskDef']
_TASKINFO = DESCRIPTOR.message_types_by_name['TaskInfo']
DatasetDef = _reflection.GeneratedProtocolMessageType('DatasetDef', (_message.Message,), {
  'DESCRIPTOR' : _DATASETDEF,
  '__module__' : 'tensorflow.core.data.service.common_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.data.DatasetDef)
  })
_sym_db.RegisterMessage(DatasetDef)

TaskDef = _reflection.GeneratedProtocolMessageType('TaskDef', (_message.Message,), {
  'DESCRIPTOR' : _TASKDEF,
  '__module__' : 'tensorflow.core.data.service.common_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.data.TaskDef)
  })
_sym_db.RegisterMessage(TaskDef)

TaskInfo = _reflection.GeneratedProtocolMessageType('TaskInfo', (_message.Message,), {
  'DESCRIPTOR' : _TASKINFO,
  '__module__' : 'tensorflow.core.data.service.common_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.data.TaskInfo)
  })
_sym_db.RegisterMessage(TaskInfo)

if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  _PROCESSINGMODEDEF._serialized_start=580
  _PROCESSINGMODEDEF._serialized_end=656
  _DATASETDEF._serialized_start=101
  _DATASETDEF._serialized_end=150
  _TASKDEF._serialized_start=153
  _TASKDEF._serialized_end=459
  _TASKINFO._serialized_start=461
  _TASKINFO._serialized_end=578
# @@protoc_insertion_point(module_scope)
