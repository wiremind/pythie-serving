"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _SplitTypeWithDefault:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _SplitTypeWithDefaultEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SplitTypeWithDefault.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    INEQUALITY_DEFAULT_LEFT: _SplitTypeWithDefault.ValueType  # 0
    INEQUALITY_DEFAULT_RIGHT: _SplitTypeWithDefault.ValueType  # 1
    EQUALITY_DEFAULT_RIGHT: _SplitTypeWithDefault.ValueType  # 3
class SplitTypeWithDefault(_SplitTypeWithDefault, metaclass=_SplitTypeWithDefaultEnumTypeWrapper):
    pass

INEQUALITY_DEFAULT_LEFT: SplitTypeWithDefault.ValueType  # 0
INEQUALITY_DEFAULT_RIGHT: SplitTypeWithDefault.ValueType  # 1
EQUALITY_DEFAULT_RIGHT: SplitTypeWithDefault.ValueType  # 3
global___SplitTypeWithDefault = SplitTypeWithDefault


class _DefaultDirection:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _DefaultDirectionEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_DefaultDirection.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    DEFAULT_LEFT: _DefaultDirection.ValueType  # 0
    """Left is the default direction."""

    DEFAULT_RIGHT: _DefaultDirection.ValueType  # 1
class DefaultDirection(_DefaultDirection, metaclass=_DefaultDirectionEnumTypeWrapper):
    pass

DEFAULT_LEFT: DefaultDirection.ValueType  # 0
"""Left is the default direction."""

DEFAULT_RIGHT: DefaultDirection.ValueType  # 1
global___DefaultDirection = DefaultDirection


class Node(google.protobuf.message.Message):
    """Node describes a node in a tree."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    LEAF_FIELD_NUMBER: builtins.int
    BUCKETIZED_SPLIT_FIELD_NUMBER: builtins.int
    CATEGORICAL_SPLIT_FIELD_NUMBER: builtins.int
    DENSE_SPLIT_FIELD_NUMBER: builtins.int
    METADATA_FIELD_NUMBER: builtins.int
    @property
    def leaf(self) -> global___Leaf: ...
    @property
    def bucketized_split(self) -> global___BucketizedSplit: ...
    @property
    def categorical_split(self) -> global___CategoricalSplit: ...
    @property
    def dense_split(self) -> global___DenseSplit: ...
    @property
    def metadata(self) -> global___NodeMetadata: ...
    def __init__(self,
        *,
        leaf: typing.Optional[global___Leaf] = ...,
        bucketized_split: typing.Optional[global___BucketizedSplit] = ...,
        categorical_split: typing.Optional[global___CategoricalSplit] = ...,
        dense_split: typing.Optional[global___DenseSplit] = ...,
        metadata: typing.Optional[global___NodeMetadata] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["bucketized_split",b"bucketized_split","categorical_split",b"categorical_split","dense_split",b"dense_split","leaf",b"leaf","metadata",b"metadata","node",b"node"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["bucketized_split",b"bucketized_split","categorical_split",b"categorical_split","dense_split",b"dense_split","leaf",b"leaf","metadata",b"metadata","node",b"node"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["node",b"node"]) -> typing.Optional[typing_extensions.Literal["leaf","bucketized_split","categorical_split","dense_split"]]: ...
global___Node = Node

class NodeMetadata(google.protobuf.message.Message):
    """NodeMetadata encodes metadata associated with each node in a tree."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    GAIN_FIELD_NUMBER: builtins.int
    ORIGINAL_LEAF_FIELD_NUMBER: builtins.int
    gain: builtins.float
    """The gain associated with this node."""

    @property
    def original_leaf(self) -> global___Leaf:
        """The original leaf node before this node was split."""
        pass
    def __init__(self,
        *,
        gain: builtins.float = ...,
        original_leaf: typing.Optional[global___Leaf] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["original_leaf",b"original_leaf"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["gain",b"gain","original_leaf",b"original_leaf"]) -> None: ...
global___NodeMetadata = NodeMetadata

class Leaf(google.protobuf.message.Message):
    """Leaves can either hold dense or sparse information."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    VECTOR_FIELD_NUMBER: builtins.int
    SPARSE_VECTOR_FIELD_NUMBER: builtins.int
    SCALAR_FIELD_NUMBER: builtins.int
    @property
    def vector(self) -> global___Vector: ...
    @property
    def sparse_vector(self) -> global___SparseVector: ...
    scalar: builtins.float
    def __init__(self,
        *,
        vector: typing.Optional[global___Vector] = ...,
        sparse_vector: typing.Optional[global___SparseVector] = ...,
        scalar: builtins.float = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["leaf",b"leaf","sparse_vector",b"sparse_vector","vector",b"vector"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["leaf",b"leaf","scalar",b"scalar","sparse_vector",b"sparse_vector","vector",b"vector"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["leaf",b"leaf"]) -> typing.Optional[typing_extensions.Literal["vector","sparse_vector"]]: ...
global___Leaf = Leaf

class Vector(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    VALUE_FIELD_NUMBER: builtins.int
    @property
    def value(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]: ...
    def __init__(self,
        *,
        value: typing.Optional[typing.Iterable[builtins.float]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["value",b"value"]) -> None: ...
global___Vector = Vector

class SparseVector(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    INDEX_FIELD_NUMBER: builtins.int
    VALUE_FIELD_NUMBER: builtins.int
    @property
    def index(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]: ...
    @property
    def value(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]: ...
    def __init__(self,
        *,
        index: typing.Optional[typing.Iterable[builtins.int]] = ...,
        value: typing.Optional[typing.Iterable[builtins.float]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["index",b"index","value",b"value"]) -> None: ...
global___SparseVector = SparseVector

class BucketizedSplit(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    FEATURE_ID_FIELD_NUMBER: builtins.int
    THRESHOLD_FIELD_NUMBER: builtins.int
    DIMENSION_ID_FIELD_NUMBER: builtins.int
    DEFAULT_DIRECTION_FIELD_NUMBER: builtins.int
    LEFT_ID_FIELD_NUMBER: builtins.int
    RIGHT_ID_FIELD_NUMBER: builtins.int
    feature_id: builtins.int
    """Float feature column and split threshold describing
    the rule feature <= threshold.
    """

    threshold: builtins.int
    dimension_id: builtins.int
    """If feature column is multivalent, this holds the index of the dimension
    for the split. Defaults to 0.
    """

    default_direction: global___DefaultDirection.ValueType
    """default direction for missing values."""

    left_id: builtins.int
    """Node children indexing into a contiguous
    vector of nodes starting from the root.
    """

    right_id: builtins.int
    def __init__(self,
        *,
        feature_id: builtins.int = ...,
        threshold: builtins.int = ...,
        dimension_id: builtins.int = ...,
        default_direction: global___DefaultDirection.ValueType = ...,
        left_id: builtins.int = ...,
        right_id: builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["default_direction",b"default_direction","dimension_id",b"dimension_id","feature_id",b"feature_id","left_id",b"left_id","right_id",b"right_id","threshold",b"threshold"]) -> None: ...
global___BucketizedSplit = BucketizedSplit

class CategoricalSplit(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    FEATURE_ID_FIELD_NUMBER: builtins.int
    VALUE_FIELD_NUMBER: builtins.int
    DIMENSION_ID_FIELD_NUMBER: builtins.int
    LEFT_ID_FIELD_NUMBER: builtins.int
    RIGHT_ID_FIELD_NUMBER: builtins.int
    feature_id: builtins.int
    """Categorical feature column and split describing the rule feature value ==
    value.
    """

    value: builtins.int
    dimension_id: builtins.int
    """If feature column is multivalent, this holds the index of the dimension
    for the split. Defaults to 0.
    """

    left_id: builtins.int
    """Node children indexing into a contiguous
    vector of nodes starting from the root.
    """

    right_id: builtins.int
    def __init__(self,
        *,
        feature_id: builtins.int = ...,
        value: builtins.int = ...,
        dimension_id: builtins.int = ...,
        left_id: builtins.int = ...,
        right_id: builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["dimension_id",b"dimension_id","feature_id",b"feature_id","left_id",b"left_id","right_id",b"right_id","value",b"value"]) -> None: ...
global___CategoricalSplit = CategoricalSplit

class DenseSplit(google.protobuf.message.Message):
    """TODO(nponomareva): move out of boosted_trees and rename to trees.proto"""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    FEATURE_ID_FIELD_NUMBER: builtins.int
    THRESHOLD_FIELD_NUMBER: builtins.int
    LEFT_ID_FIELD_NUMBER: builtins.int
    RIGHT_ID_FIELD_NUMBER: builtins.int
    feature_id: builtins.int
    """Float feature column and split threshold describing
    the rule feature <= threshold.
    """

    threshold: builtins.float
    left_id: builtins.int
    """Node children indexing into a contiguous
    vector of nodes starting from the root.
    """

    right_id: builtins.int
    def __init__(self,
        *,
        feature_id: builtins.int = ...,
        threshold: builtins.float = ...,
        left_id: builtins.int = ...,
        right_id: builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["feature_id",b"feature_id","left_id",b"left_id","right_id",b"right_id","threshold",b"threshold"]) -> None: ...
global___DenseSplit = DenseSplit

class Tree(google.protobuf.message.Message):
    """Tree describes a list of connected nodes.
    Node 0 must be the root and can carry any payload including a leaf
    in the case of representing the bias.
    Note that each node id is implicitly its index in the list of nodes.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    NODES_FIELD_NUMBER: builtins.int
    @property
    def nodes(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Node]: ...
    def __init__(self,
        *,
        nodes: typing.Optional[typing.Iterable[global___Node]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["nodes",b"nodes"]) -> None: ...
global___Tree = Tree

class TreeMetadata(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    class PostPruneNodeUpdate(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor
        NEW_NODE_ID_FIELD_NUMBER: builtins.int
        LOGIT_CHANGE_FIELD_NUMBER: builtins.int
        new_node_id: builtins.int
        @property
        def logit_change(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]: ...
        def __init__(self,
            *,
            new_node_id: builtins.int = ...,
            logit_change: typing.Optional[typing.Iterable[builtins.float]] = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["logit_change",b"logit_change","new_node_id",b"new_node_id"]) -> None: ...

    NUM_LAYERS_GROWN_FIELD_NUMBER: builtins.int
    IS_FINALIZED_FIELD_NUMBER: builtins.int
    POST_PRUNED_NODES_META_FIELD_NUMBER: builtins.int
    num_layers_grown: builtins.int
    """Number of layers grown for this tree."""

    is_finalized: builtins.bool
    """Whether the tree is finalized in that no more layers can be grown."""

    @property
    def post_pruned_nodes_meta(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TreeMetadata.PostPruneNodeUpdate]:
        """If tree was finalized and post pruning happened, it is possible that cache
        still refers to some nodes that were deleted or that the node ids changed
        (e.g. node id 5 became node id 2 due to pruning of the other branch).
        The mapping below allows us to understand where the old ids now map to and
        how the values should be adjusted due to post-pruning.
        The size of the list should be equal to the number of nodes in the tree
        before post-pruning happened.
        If the node was pruned, it will have new_node_id equal to the id of a node
        that this node was collapsed into. For a node that didn't get pruned, it is
        possible that its id still changed, so new_node_id will have the
        corresponding id in the pruned tree.
        If post-pruning didn't happen, or it did and it had no effect (e.g. no
        nodes got pruned), this list will be empty.
        """
        pass
    def __init__(self,
        *,
        num_layers_grown: builtins.int = ...,
        is_finalized: builtins.bool = ...,
        post_pruned_nodes_meta: typing.Optional[typing.Iterable[global___TreeMetadata.PostPruneNodeUpdate]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["is_finalized",b"is_finalized","num_layers_grown",b"num_layers_grown","post_pruned_nodes_meta",b"post_pruned_nodes_meta"]) -> None: ...
global___TreeMetadata = TreeMetadata

class GrowingMetadata(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    NUM_TREES_ATTEMPTED_FIELD_NUMBER: builtins.int
    NUM_LAYERS_ATTEMPTED_FIELD_NUMBER: builtins.int
    LAST_LAYER_NODE_START_FIELD_NUMBER: builtins.int
    LAST_LAYER_NODE_END_FIELD_NUMBER: builtins.int
    num_trees_attempted: builtins.int
    """Number of trees that we have attempted to build. After pruning, these
    trees might have been removed.
    """

    num_layers_attempted: builtins.int
    """Number of layers that we have attempted to build. After pruning, these
    layers might have been removed.
    """

    last_layer_node_start: builtins.int
    """The start (inclusive) and end (exclusive) ids of the nodes in the latest
    layer of the latest tree.
    """

    last_layer_node_end: builtins.int
    def __init__(self,
        *,
        num_trees_attempted: builtins.int = ...,
        num_layers_attempted: builtins.int = ...,
        last_layer_node_start: builtins.int = ...,
        last_layer_node_end: builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["last_layer_node_end",b"last_layer_node_end","last_layer_node_start",b"last_layer_node_start","num_layers_attempted",b"num_layers_attempted","num_trees_attempted",b"num_trees_attempted"]) -> None: ...
global___GrowingMetadata = GrowingMetadata

class TreeEnsemble(google.protobuf.message.Message):
    """TreeEnsemble describes an ensemble of decision trees."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    TREES_FIELD_NUMBER: builtins.int
    TREE_WEIGHTS_FIELD_NUMBER: builtins.int
    TREE_METADATA_FIELD_NUMBER: builtins.int
    GROWING_METADATA_FIELD_NUMBER: builtins.int
    @property
    def trees(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Tree]: ...
    @property
    def tree_weights(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]: ...
    @property
    def tree_metadata(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TreeMetadata]: ...
    @property
    def growing_metadata(self) -> global___GrowingMetadata:
        """Metadata that is used during the training."""
        pass
    def __init__(self,
        *,
        trees: typing.Optional[typing.Iterable[global___Tree]] = ...,
        tree_weights: typing.Optional[typing.Iterable[builtins.float]] = ...,
        tree_metadata: typing.Optional[typing.Iterable[global___TreeMetadata]] = ...,
        growing_metadata: typing.Optional[global___GrowingMetadata] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["growing_metadata",b"growing_metadata"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["growing_metadata",b"growing_metadata","tree_metadata",b"tree_metadata","tree_weights",b"tree_weights","trees",b"trees"]) -> None: ...
global___TreeEnsemble = TreeEnsemble

class DebugOutput(google.protobuf.message.Message):
    """DebugOutput contains outputs useful for debugging/model interpretation, at
    the individual example-level. Debug outputs that are available to the user
    are: 1) Directional feature contributions (DFCs) 2) Node IDs for ensemble
    prediction paths 3) Leaf node IDs.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    FEATURE_IDS_FIELD_NUMBER: builtins.int
    LOGITS_PATH_FIELD_NUMBER: builtins.int
    LEAF_NODE_IDS_FIELD_NUMBER: builtins.int
    @property
    def feature_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]:
        """Return the logits and associated feature splits across prediction paths for
        each tree, for every example, at predict time. We will use these values to
        compute DFCs in Python, by subtracting each child prediction from its
        parent prediction and associating this change with its respective feature
        id.
        """
        pass
    @property
    def logits_path(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]: ...
    @property
    def leaf_node_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]:
        """Return the node_id for each leaf node we reach in our prediction path.
        TODO(crawles): return 4) Node IDs for ensemble prediction path
        """
        pass
    def __init__(self,
        *,
        feature_ids: typing.Optional[typing.Iterable[builtins.int]] = ...,
        logits_path: typing.Optional[typing.Iterable[builtins.float]] = ...,
        leaf_node_ids: typing.Optional[typing.Iterable[builtins.int]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["feature_ids",b"feature_ids","leaf_node_ids",b"leaf_node_ids","logits_path",b"logits_path"]) -> None: ...
global___DebugOutput = DebugOutput
