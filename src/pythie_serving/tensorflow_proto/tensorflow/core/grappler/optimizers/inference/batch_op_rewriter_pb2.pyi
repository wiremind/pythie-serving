"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.message
import google.protobuf.wrappers_pb2
import sys

if sys.version_info >= (3, 8):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

@typing_extensions.final
class BatchOpRewriteConfig(google.protobuf.message.Message):
    """Config for the batch op rewriter. This should be serialized
    and set a param in RewriterConfig with key kBatchOpRewriteParamKey.
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    @typing_extensions.final
    class AdaptiveBatchSchedulerOption(google.protobuf.message.Message):
        """The options for tensorflow::serving::AdaptiveSharedBatchScheduler.
        See AdaptiveSharedBatchScheduler::Options for meaning of each field.

        NOTE:
        Leave this unset to pick up default settings which should work for most
        scenarios.

        Example scenarios when tuning helps:
        * Latency sensitive
        """

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        MIN_INFLIGHT_BATCHES_LIMIT_FIELD_NUMBER: builtins.int
        INITIAL_INFLIGHT_BATCHES_LIMIT_FIELD_NUMBER: builtins.int
        MAX_INFLIGHT_BATCHES_LIMIT_FIELD_NUMBER: builtins.int
        BATCHES_TO_AVERAGE_OVER_FIELD_NUMBER: builtins.int
        @property
        def min_inflight_batches_limit(self) -> google.protobuf.wrappers_pb2.UInt32Value: ...
        @property
        def initial_inflight_batches_limit(self) -> google.protobuf.wrappers_pb2.UInt32Value: ...
        @property
        def max_inflight_batches_limit(self) -> google.protobuf.wrappers_pb2.UInt32Value: ...
        @property
        def batches_to_average_over(self) -> google.protobuf.wrappers_pb2.UInt32Value:
            """You can use QPS as a reference to decide how quickly to react to workload
            changes.
            """
        def __init__(
            self,
            *,
            min_inflight_batches_limit: google.protobuf.wrappers_pb2.UInt32Value | None = ...,
            initial_inflight_batches_limit: google.protobuf.wrappers_pb2.UInt32Value | None = ...,
            max_inflight_batches_limit: google.protobuf.wrappers_pb2.UInt32Value | None = ...,
            batches_to_average_over: google.protobuf.wrappers_pb2.UInt32Value | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["batches_to_average_over", b"batches_to_average_over", "initial_inflight_batches_limit", b"initial_inflight_batches_limit", "max_inflight_batches_limit", b"max_inflight_batches_limit", "min_inflight_batches_limit", b"min_inflight_batches_limit"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["batches_to_average_over", b"batches_to_average_over", "initial_inflight_batches_limit", b"initial_inflight_batches_limit", "max_inflight_batches_limit", b"max_inflight_batches_limit", "min_inflight_batches_limit", b"min_inflight_batches_limit"]) -> None: ...

    @typing_extensions.final
    class ModelSchedulerOptionsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: builtins.str
        @property
        def value(self) -> global___BatchOpRewriteConfig.AdaptiveBatchSchedulerOption: ...
        def __init__(
            self,
            *,
            key: builtins.str = ...,
            value: global___BatchOpRewriteConfig.AdaptiveBatchSchedulerOption | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["value", b"value"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...

    ENABLE_ADAPTIVE_SHARED_BATCHING_THREAD_POOL_FIELD_NUMBER: builtins.int
    MODEL_SCHEDULER_OPTIONS_FIELD_NUMBER: builtins.int
    enable_adaptive_shared_batching_thread_pool: builtins.bool
    @property
    def model_scheduler_options(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, global___BatchOpRewriteConfig.AdaptiveBatchSchedulerOption]:
        """Keyed by model name, meaning all batch-ops in one saved model would use the
        same adaptive-batch-scheduler option.
        """
    def __init__(
        self,
        *,
        enable_adaptive_shared_batching_thread_pool: builtins.bool = ...,
        model_scheduler_options: collections.abc.Mapping[builtins.str, global___BatchOpRewriteConfig.AdaptiveBatchSchedulerOption] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["enable_adaptive_shared_batching_thread_pool", b"enable_adaptive_shared_batching_thread_pool", "model_scheduler_options", b"model_scheduler_options"]) -> None: ...

global___BatchOpRewriteConfig = BatchOpRewriteConfig
