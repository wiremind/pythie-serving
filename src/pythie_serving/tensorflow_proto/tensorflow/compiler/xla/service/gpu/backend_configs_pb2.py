# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow/compiler/xla/service/gpu/backend_configs.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from pythie_serving.tensorflow_proto.tensorflow.compiler.xla import xla_data_pb2 as tensorflow_dot_compiler_dot_xla_dot_xla__data__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n9tensorflow/compiler/xla/service/gpu/backend_configs.proto\x12\x07xla.gpu\x1a&tensorflow/compiler/xla/xla_data.proto\"\x95\x01\n\x16\x43udnnConvBackendConfig\x12\x11\n\talgorithm\x18\x01 \x01(\x03\x12\x1a\n\x12tensor_ops_enabled\x18\x02 \x01(\x08\x12\x19\n\x11\x63onv_result_scale\x18\x04 \x01(\x01\x12\x17\n\x0f\x61\x63tivation_mode\x18\x03 \x01(\x03\x12\x18\n\x10side_input_scale\x18\x05 \x01(\x01\"\xc1\x01\n\x11GemmBackendConfig\x12\x1c\n\x12selected_algorithm\x18\x01 \x01(\x03H\x00\x12\x12\n\nalpha_real\x18\x02 \x01(\x01\x12\x12\n\nalpha_imag\x18\t \x01(\x01\x12\x0c\n\x04\x62\x65ta\x18\x03 \x01(\x01\x12\x37\n\x15\x64ot_dimension_numbers\x18\x07 \x01(\x0b\x32\x18.xla.DotDimensionNumbers\x12\x12\n\nbatch_size\x18\x08 \x01(\x03\x42\x0b\n\talgorithm\"h\n\x14\x42itcastBackendConfig\x12\'\n\rsource_layout\x18\x01 \x01(\x0b\x32\x10.xla.LayoutProto\x12\'\n\rresult_layout\x18\x02 \x01(\x0b\x32\x10.xla.LayoutProtob\x06proto3')



_CUDNNCONVBACKENDCONFIG = DESCRIPTOR.message_types_by_name['CudnnConvBackendConfig']
_GEMMBACKENDCONFIG = DESCRIPTOR.message_types_by_name['GemmBackendConfig']
_BITCASTBACKENDCONFIG = DESCRIPTOR.message_types_by_name['BitcastBackendConfig']
CudnnConvBackendConfig = _reflection.GeneratedProtocolMessageType('CudnnConvBackendConfig', (_message.Message,), {
  'DESCRIPTOR' : _CUDNNCONVBACKENDCONFIG,
  '__module__' : 'tensorflow.compiler.xla.service.gpu.backend_configs_pb2'
  # @@protoc_insertion_point(class_scope:xla.gpu.CudnnConvBackendConfig)
  })
_sym_db.RegisterMessage(CudnnConvBackendConfig)

GemmBackendConfig = _reflection.GeneratedProtocolMessageType('GemmBackendConfig', (_message.Message,), {
  'DESCRIPTOR' : _GEMMBACKENDCONFIG,
  '__module__' : 'tensorflow.compiler.xla.service.gpu.backend_configs_pb2'
  # @@protoc_insertion_point(class_scope:xla.gpu.GemmBackendConfig)
  })
_sym_db.RegisterMessage(GemmBackendConfig)

BitcastBackendConfig = _reflection.GeneratedProtocolMessageType('BitcastBackendConfig', (_message.Message,), {
  'DESCRIPTOR' : _BITCASTBACKENDCONFIG,
  '__module__' : 'tensorflow.compiler.xla.service.gpu.backend_configs_pb2'
  # @@protoc_insertion_point(class_scope:xla.gpu.BitcastBackendConfig)
  })
_sym_db.RegisterMessage(BitcastBackendConfig)

if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  _CUDNNCONVBACKENDCONFIG._serialized_start=111
  _CUDNNCONVBACKENDCONFIG._serialized_end=260
  _GEMMBACKENDCONFIG._serialized_start=263
  _GEMMBACKENDCONFIG._serialized_end=456
  _BITCASTBACKENDCONFIG._serialized_start=458
  _BITCASTBACKENDCONFIG._serialized_end=562
# @@protoc_insertion_point(module_scope)
