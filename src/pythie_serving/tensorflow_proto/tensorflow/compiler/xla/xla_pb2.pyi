"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import tensorflow.compiler.xla.service.hlo_pb2
import tensorflow.compiler.xla.xla_data_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class DebugOptions(google.protobuf.message.Message):
    """Debugging options for XLA. These options may change at any time - there are
    no guarantees about backward or forward compatibility for these fields.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    class _StepMarkerLocation:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _StepMarkerLocationEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[DebugOptions._StepMarkerLocation.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        STEP_MARK_AT_ENTRY: DebugOptions._StepMarkerLocation.ValueType  # 0
        """Generate a step marker at the program entry. This handles the case where
        each step is done by one or multiple program execution(s). Only the first
        program will be tagged for generating a step marker at the program entry.
        This is the default.
        """

        STEP_MARK_AT_TOP_LEVEL_WHILE_LOOP: DebugOptions._StepMarkerLocation.ValueType  # 1
        """Generate a step marker at each iteration of the top level while loop,
        which is assumed to be a training loop.
        """

        STEP_MARK_AT_SECOND_LEVEL_WHILE_LOOP: DebugOptions._StepMarkerLocation.ValueType  # 3
        """Generate a step marker at each iteration of the second level while loops,
        which is assumed to be a training or eval loop.
        """

        STEP_MARK_NONE: DebugOptions._StepMarkerLocation.ValueType  # 2
        """No step marker generated."""

    class StepMarkerLocation(_StepMarkerLocation, metaclass=_StepMarkerLocationEnumTypeWrapper):
        pass

    STEP_MARK_AT_ENTRY: DebugOptions.StepMarkerLocation.ValueType  # 0
    """Generate a step marker at the program entry. This handles the case where
    each step is done by one or multiple program execution(s). Only the first
    program will be tagged for generating a step marker at the program entry.
    This is the default.
    """

    STEP_MARK_AT_TOP_LEVEL_WHILE_LOOP: DebugOptions.StepMarkerLocation.ValueType  # 1
    """Generate a step marker at each iteration of the top level while loop,
    which is assumed to be a training loop.
    """

    STEP_MARK_AT_SECOND_LEVEL_WHILE_LOOP: DebugOptions.StepMarkerLocation.ValueType  # 3
    """Generate a step marker at each iteration of the second level while loops,
    which is assumed to be a training or eval loop.
    """

    STEP_MARK_NONE: DebugOptions.StepMarkerLocation.ValueType  # 2
    """No step marker generated."""


    class XlaBackendExtraOptionsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text
        value: typing.Text
        def __init__(self,
            *,
            key: typing.Text = ...,
            value: typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    XLA_HLO_GRAPH_ADDRESSES_FIELD_NUMBER: builtins.int
    XLA_HLO_PROFILE_FIELD_NUMBER: builtins.int
    XLA_DISABLE_HLO_PASSES_FIELD_NUMBER: builtins.int
    XLA_ENABLE_HLO_PASSES_ONLY_FIELD_NUMBER: builtins.int
    XLA_DISABLE_ALL_HLO_PASSES_FIELD_NUMBER: builtins.int
    XLA_BACKEND_OPTIMIZATION_LEVEL_FIELD_NUMBER: builtins.int
    XLA_EMBED_IR_IN_EXECUTABLE_FIELD_NUMBER: builtins.int
    XLA_ELIMINATE_HLO_IMPLICIT_BROADCAST_FIELD_NUMBER: builtins.int
    XLA_CPU_MULTI_THREAD_EIGEN_FIELD_NUMBER: builtins.int
    XLA_GPU_CUDA_DATA_DIR_FIELD_NUMBER: builtins.int
    XLA_GPU_FTZ_FIELD_NUMBER: builtins.int
    XLA_GPU_DISABLE_MULTI_STREAMING_FIELD_NUMBER: builtins.int
    XLA_GPU_USE_RANDOM_STREAMS_FIELD_NUMBER: builtins.int
    XLA_LLVM_ENABLE_ALIAS_SCOPE_METADATA_FIELD_NUMBER: builtins.int
    XLA_LLVM_ENABLE_NOALIAS_METADATA_FIELD_NUMBER: builtins.int
    XLA_LLVM_ENABLE_INVARIANT_LOAD_METADATA_FIELD_NUMBER: builtins.int
    XLA_LLVM_DISABLE_EXPENSIVE_PASSES_FIELD_NUMBER: builtins.int
    XLA_TEST_ALL_OUTPUT_LAYOUTS_FIELD_NUMBER: builtins.int
    XLA_TEST_ALL_INPUT_LAYOUTS_FIELD_NUMBER: builtins.int
    XLA_HLO_GRAPH_SHARDING_COLOR_FIELD_NUMBER: builtins.int
    XLA_GPU_USE_CUDNN_BATCHNORM_FIELD_NUMBER: builtins.int
    XLA_CPU_USE_MKL_DNN_FIELD_NUMBER: builtins.int
    XLA_GPU_MAX_KERNEL_UNROLL_FACTOR_FIELD_NUMBER: builtins.int
    XLA_CPU_ENABLE_FAST_MATH_FIELD_NUMBER: builtins.int
    XLA_CPU_FAST_MATH_HONOR_NANS_FIELD_NUMBER: builtins.int
    XLA_CPU_FAST_MATH_HONOR_INFS_FIELD_NUMBER: builtins.int
    XLA_CPU_FAST_MATH_HONOR_DIVISION_FIELD_NUMBER: builtins.int
    XLA_CPU_FAST_MATH_HONOR_FUNCTIONS_FIELD_NUMBER: builtins.int
    XLA_CPU_ENABLE_FAST_MIN_MAX_FIELD_NUMBER: builtins.int
    XLA_GPU_ENABLE_FAST_MIN_MAX_FIELD_NUMBER: builtins.int
    XLA_ALLOW_EXCESS_PRECISION_FIELD_NUMBER: builtins.int
    XLA_GPU_CRASH_ON_VERIFICATION_FAILURES_FIELD_NUMBER: builtins.int
    XLA_GPU_AUTOTUNE_LEVEL_FIELD_NUMBER: builtins.int
    XLA_FORCE_HOST_PLATFORM_DEVICE_COUNT_FIELD_NUMBER: builtins.int
    XLA_GPU_DISABLE_GPUASM_OPTIMIZATIONS_FIELD_NUMBER: builtins.int
    XLA_HLO_EVALUATOR_USE_FAST_PATH_FIELD_NUMBER: builtins.int
    XLA_ALLOW_SCALAR_INDEX_DYNAMIC_OPS_FIELD_NUMBER: builtins.int
    XLA_STEP_MARKER_LOCATION_FIELD_NUMBER: builtins.int
    XLA_DUMP_TO_FIELD_NUMBER: builtins.int
    XLA_DUMP_HLO_MODULE_RE_FIELD_NUMBER: builtins.int
    XLA_DUMP_HLO_PASS_RE_FIELD_NUMBER: builtins.int
    XLA_DUMP_HLO_AS_TEXT_FIELD_NUMBER: builtins.int
    XLA_DUMP_HLO_AS_PROTO_FIELD_NUMBER: builtins.int
    XLA_DUMP_HLO_AS_DOT_FIELD_NUMBER: builtins.int
    XLA_DUMP_HLO_AS_URL_FIELD_NUMBER: builtins.int
    XLA_DUMP_HLO_AS_HTML_FIELD_NUMBER: builtins.int
    XLA_DUMP_FUSION_VISUALIZATION_FIELD_NUMBER: builtins.int
    XLA_DUMP_HLO_SNAPSHOTS_FIELD_NUMBER: builtins.int
    XLA_DUMP_INCLUDE_TIMESTAMP_FIELD_NUMBER: builtins.int
    XLA_DUMP_MAX_HLO_MODULES_FIELD_NUMBER: builtins.int
    XLA_DUMP_MODULE_METADATA_FIELD_NUMBER: builtins.int
    XLA_DUMP_COMPRESS_PROTOS_FIELD_NUMBER: builtins.int
    XLA_GPU_FORCE_CONV_NCHW_FIELD_NUMBER: builtins.int
    XLA_GPU_FORCE_CONV_NHWC_FIELD_NUMBER: builtins.int
    XLA_GPU_PTX_FILE_FIELD_NUMBER: builtins.int
    XLA_GPU_ALGORITHM_DENYLIST_PATH_FIELD_NUMBER: builtins.int
    XLA_GPU_DETERMINISTIC_REDUCTIONS_FIELD_NUMBER: builtins.int
    XLA_TPU_DETECT_NAN_FIELD_NUMBER: builtins.int
    XLA_TPU_DETECT_INF_FIELD_NUMBER: builtins.int
    XLA_CPU_ENABLE_XPROF_TRACEME_FIELD_NUMBER: builtins.int
    XLA_GPU_UNSAFE_FALLBACK_TO_DRIVER_ON_PTXAS_NOT_FOUND_FIELD_NUMBER: builtins.int
    XLA_GPU_ASM_EXTRA_FLAGS_FIELD_NUMBER: builtins.int
    XLA_MULTIHEAP_SIZE_CONSTRAINT_PER_HEAP_FIELD_NUMBER: builtins.int
    XLA_DETAILED_LOGGING_AND_DUMPING_FIELD_NUMBER: builtins.int
    XLA_GPU_FORCE_COMPILATION_PARALLELISM_FIELD_NUMBER: builtins.int
    XLA_GPU_DETERMINISTIC_OPS_FIELD_NUMBER: builtins.int
    XLA_GPU_LLVM_IR_FILE_FIELD_NUMBER: builtins.int
    XLA_GPU_ENABLE_ASYNC_ALL_REDUCE_FIELD_NUMBER: builtins.int
    XLA_BACKEND_EXTRA_OPTIONS_FIELD_NUMBER: builtins.int
    xla_hlo_graph_addresses: builtins.bool
    """Show addresses of HLO ops in graph dump."""

    xla_hlo_profile: builtins.bool
    """Instrument the computation to collect per-HLO cycle counts."""

    @property
    def xla_disable_hlo_passes(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """List of HLO passes to disable/enable. These names must exactly match the
        pass names as specified by the HloPassInterface::name() method.

        At least one of xla_disable_hlo_passes and xla_enable_hlo_passes_only must
        be empty.
        """
        pass
    @property
    def xla_enable_hlo_passes_only(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]: ...
    xla_disable_all_hlo_passes: builtins.bool
    """Disables all HLO passes.  Notes that some passes are necessary for
    correctness and the invariants that must be satisfied by "fully optimized"
    HLO are different for different devices and may change over time.  The only
    "guarantee", such as it is, is that if you compile XLA and dump the
    optimized HLO for some graph, you should be able to run it again on the
    same device with the same build of XLA.
    """

    xla_backend_optimization_level: builtins.int
    """Numerical optimization level for the XLA compiler backend; the specific
    interpretation of this value is left to the backends.
    """

    xla_embed_ir_in_executable: builtins.bool
    """Embed the compiler IR as a string in the executable."""

    xla_eliminate_hlo_implicit_broadcast: builtins.bool
    """Eliminate implicit broadcasts when lowering user computations to HLO
    instructions; use explicit broadcast instead.
    """

    xla_cpu_multi_thread_eigen: builtins.bool
    """When generating calls to Eigen in the CPU backend, use multi-threaded Eigen
    mode.
    """

    xla_gpu_cuda_data_dir: typing.Text
    """Path to directory with cuda/ptx tools and libraries."""

    xla_gpu_ftz: builtins.bool
    """Enable flush-to-zero semantics in the GPU backend."""

    xla_gpu_disable_multi_streaming: builtins.bool
    """Disable multi-streaming in the GPU backend."""

    xla_gpu_use_random_streams: builtins.bool
    """Debugging feature: if enabled, the GPU backend will assign HLO operators to
    randomly chosen streams. This is intended to trigger concurrency bugs.
    """

    xla_llvm_enable_alias_scope_metadata: builtins.bool
    """If true, in LLVM-based backends, emit !alias.scope metadata in
    generated IR.
    """

    xla_llvm_enable_noalias_metadata: builtins.bool
    """If true, in LLVM-based backends, emit !noalias metadata in the
    generated IR.
    """

    xla_llvm_enable_invariant_load_metadata: builtins.bool
    """If true, in LLVM-based backends, emit !invariant.load metadata in
    the generated IR.
    """

    xla_llvm_disable_expensive_passes: builtins.bool
    """If true, a set of expensive LLVM optimization passes will not be run."""

    xla_test_all_output_layouts: builtins.bool
    """This is used by ClientLibraryTestBase::ComputeAndCompare*. If true, the
    computation will run n! times with all permunations of layouts for the
    output shape in rank n. For example, with a 3D shape, all permutations of
    the set {0, 1, 2} are tried.
    """

    xla_test_all_input_layouts: builtins.bool
    """This is used by ClientLibraryTestBase::ComputeAndCompare*. If true, the
    computation will run for all permunations of layouts of all input
    arguments. For example, with 2 input arguments in 2D and 4D shapes, the
    computation will run 2! * 4! times.
    """

    xla_hlo_graph_sharding_color: builtins.bool
    """Assign colors based on sharding information when generating the Graphviz
    HLO graph.
    """

    xla_gpu_use_cudnn_batchnorm: builtins.bool
    """If true, the GPU backend is free to use cudnn for HLO batch normalization
    ops.
    """

    xla_cpu_use_mkl_dnn: builtins.bool
    """Generate calls to MKL-DNN in the CPU backend."""

    xla_gpu_max_kernel_unroll_factor: builtins.int
    """Maximum kernel unroll factor for the GPU backend."""

    xla_cpu_enable_fast_math: builtins.bool
    """When true, "unsafe" mathematical optimizations are enabled. These
    transformations include but are not limited to:

     - Reducing the precision of operations (e.g. using an approximate sin
       function, or transforming x/y into x * (1/y)).
     - Assuming that operations never produce or consume NaN or +/- Inf (this
       behavior can be adjusted using xla_cpu_fast_math_allow_{nans|infs}).
     - Assuming that +0 and -0 are indistinguishable.
    """

    xla_cpu_fast_math_honor_nans: builtins.bool
    """When xla_cpu_enable_fast_math is true then this controls whether we allow
    operations to produce NaNs.  Ignored when xla_cpu_enable_fast_math is
    false.
    """

    xla_cpu_fast_math_honor_infs: builtins.bool
    """When xla_cpu_enable_fast_math is true then this controls whether we allow
    operations to produce infinites. Ignored when xla_cpu_enable_fast_math is
    false.
    """

    xla_cpu_fast_math_honor_division: builtins.bool
    """When xla_cpu_enable_fast_math is true then this controls whether we forbid
    to use the reciprocal of an argument instead of division. Ignored when
    xla_cpu_enable_fast_math is false.
    """

    xla_cpu_fast_math_honor_functions: builtins.bool
    """When xla_cpu_enable_fast_math is true then this controls whether we forbid
    to approximate calculations for functions. Ignored when
    xla_cpu_enable_fast_math is false.
    """

    xla_cpu_enable_fast_min_max: builtins.bool
    """When false we lower the Minimum and Maximum hlos in the CPU backend such
    that Min(NotNaN, NaN) = Min(NaN, NotNaN) = NaN.  In other words, if flag
    this is false we always propagate NaNs through Min and Max.

    Note, this does not correspond to the exact same behavior as the gpu flag
    below!
    """

    xla_gpu_enable_fast_min_max: builtins.bool
    """When true we lower the Minimum and Maximum hlos in the GPU backend such
    that Min(NotNaN, NaN) = Min(NaN, NotNaN) = NotNaN.  In other words, if flag
    this is true we don't propagate NaNs through Min and Max.

    Note, this does not correspond to the exact same behavior as the cpu flag
    above!
    """

    xla_allow_excess_precision: builtins.bool
    """Allows xla to increase the output precision of floating point operations."""

    xla_gpu_crash_on_verification_failures: builtins.bool
    """Crashes the program when any kind of verification fails, instead of just
    logging the failures. One example is cross checking of convolution results
    among different algorithms.
    """

    xla_gpu_autotune_level: builtins.int
    """0:   Disable gemm and convolution autotuning.
    1:   Enable autotuning, but disable correctness checking.
    2:   Also set output buffers to random numbers during autotuning.
    3:   Also reset output buffers to random numbers after autotuning each
         algorithm.
    4+:  Also check for correct outputs and for out-of-bounds reads/writes.

    Default: 4.
    """

    xla_force_host_platform_device_count: builtins.int
    """Force the host platform to pretend that there are these many host
    "devices".  All these devices are backed by the same threadpool.  Defaults
    to 1.

    Setting this to anything other than 1 can increase overhead from context
    switching but we let the user override this behavior to help run tests on
    the host that run models in parallel across multiple devices.
    """

    xla_gpu_disable_gpuasm_optimizations: builtins.bool
    """If set to true XLA:GPU invokes `ptxas` with -O0 (default is -O3)."""

    xla_hlo_evaluator_use_fast_path: builtins.bool
    """Enable fast math with eigen in the HLO evaluator."""

    xla_allow_scalar_index_dynamic_ops: builtins.bool
    """Temporary option to allow support for both the R1 and the scalar index
    versions of DynamicSlice and DynamicUpdateSlice. Only used for testing.
    """

    xla_step_marker_location: global___DebugOptions.StepMarkerLocation.ValueType
    """Option to emit a target-specific marker to indicate the start of a training
    step. The location of the marker (if any) is determined by the option
    value.
    """

    xla_dump_to: typing.Text
    """
    BEGIN flags controlling dumping HLO modules for debugging.

    When dumping is enabled, HLO modules dumped at the very beginning and end
    of compilation, and optionally also during the pass pipeline.

    In general, if you set one of these flags, we will try to infer reasonable
    defaults for the others.  For example:

     * Setting --xla_dump_to=/tmp/foo without specifying a format
       with --xla_dump_hlo_as_* will turn on --xla_dump_hlo_as_text.

     * Setting --xla_dump_hlo_as_text without specifying --xla_dump_to will
       dump to stdout.

    Directory to dump into.
    """

    xla_dump_hlo_module_re: typing.Text
    """If specified, will only dump modules which match this regexp."""

    xla_dump_hlo_pass_re: typing.Text
    """If this flag is specified, will also HLO before and after passes that match
    this regular expression.  Set to .* to dump before/after all passes.
    """

    xla_dump_hlo_as_text: builtins.bool
    """Specifies the format that HLO is dumped in.  Multiple of these may be
    specified.
    """

    xla_dump_hlo_as_proto: builtins.bool
    xla_dump_hlo_as_dot: builtins.bool
    xla_dump_hlo_as_url: builtins.bool
    xla_dump_hlo_as_html: builtins.bool
    """Dump HLO graphs as an HTML (DOT -> SVG inlined in HTML)"""

    xla_dump_fusion_visualization: builtins.bool
    """Dump the visualization of the fusion progress."""

    xla_dump_hlo_snapshots: builtins.bool
    """If true, every time an HLO module is run, we will dump an HloSnapshot
    (essentially, a serialized module plus its inputs) to the --xla_dump_to
    directory.
    """

    xla_dump_include_timestamp: builtins.bool
    """Include a timestamp in the dumped filenames."""

    xla_dump_max_hlo_modules: builtins.int
    """Max number of hlo module dumps in a directory. Set to < 0 for unbounded."""

    xla_dump_module_metadata: builtins.bool
    """Dump HloModuleMetadata as a text proto for each HLO module."""

    xla_dump_compress_protos: builtins.bool
    """GZip-compress protos dumped via --xla_dump_hlo_as_proto."""

    xla_gpu_force_conv_nchw: builtins.bool
    """
    END flags controlling dumping HLO modules.

    Overrides for XLA GPU's convolution layout heuristic.
    """

    xla_gpu_force_conv_nhwc: builtins.bool
    @property
    def xla_gpu_ptx_file(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """Paths to files with ptx code."""
        pass
    xla_gpu_algorithm_denylist_path: typing.Text
    """Denylist for cuDNN convolutions."""

    xla_gpu_deterministic_reductions: builtins.bool
    """Guarantee run-to-run determinism from reductions on XLA:GPU."""

    xla_tpu_detect_nan: builtins.bool
    """Debug options that trigger execution errors when NaN or Inf are detected."""

    xla_tpu_detect_inf: builtins.bool
    xla_cpu_enable_xprof_traceme: builtins.bool
    """True if TraceMe annotations are enabled for XLA:CPU."""

    xla_gpu_unsafe_fallback_to_driver_on_ptxas_not_found: builtins.bool
    """It is usually preferable to not fallback to the driver; it can consume more
    memory, or have bugs.
    """

    xla_gpu_asm_extra_flags: typing.Text
    """Extra parameters to pass the GPU assembler."""

    xla_multiheap_size_constraint_per_heap: builtins.int
    """Per-heap size constraint. New heaps will be created if per-heap max size is
    reached.
    """

    xla_detailed_logging_and_dumping: builtins.bool
    """Enable detailed logging into vlog and xla dumping. If this is disabled, no
    compilation summary will be printed in the end of computation and no hlo
    modules will be dumped.
    """

    xla_gpu_force_compilation_parallelism: builtins.int
    """Overrides normal multi-threaded compilation settting to use this many
    threads. Setting to 0 (the default value) means no enforcement.
    """

    xla_gpu_deterministic_ops: builtins.bool
    """Guarantees run-to-run determinism. At present, the HLO ops Scatter and
    SelectAndScatter do not have deterministic XLA:GPU implementations.
    Compilation errors out if these ops are encountered.
    """

    @property
    def xla_gpu_llvm_ir_file(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """Paths to files with LLVM code."""
        pass
    xla_gpu_enable_async_all_reduce: builtins.bool
    """Convert synchronous all-reduces ops into asynchronous."""

    @property
    def xla_backend_extra_options(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """Next id: 153

        Extra options to pass to the compilation backend (e.g. LLVM); specific
        interpretation of these values is left to the backend.
        """
        pass
    def __init__(self,
        *,
        xla_hlo_graph_addresses: builtins.bool = ...,
        xla_hlo_profile: builtins.bool = ...,
        xla_disable_hlo_passes: typing.Optional[typing.Iterable[typing.Text]] = ...,
        xla_enable_hlo_passes_only: typing.Optional[typing.Iterable[typing.Text]] = ...,
        xla_disable_all_hlo_passes: builtins.bool = ...,
        xla_backend_optimization_level: builtins.int = ...,
        xla_embed_ir_in_executable: builtins.bool = ...,
        xla_eliminate_hlo_implicit_broadcast: builtins.bool = ...,
        xla_cpu_multi_thread_eigen: builtins.bool = ...,
        xla_gpu_cuda_data_dir: typing.Text = ...,
        xla_gpu_ftz: builtins.bool = ...,
        xla_gpu_disable_multi_streaming: builtins.bool = ...,
        xla_gpu_use_random_streams: builtins.bool = ...,
        xla_llvm_enable_alias_scope_metadata: builtins.bool = ...,
        xla_llvm_enable_noalias_metadata: builtins.bool = ...,
        xla_llvm_enable_invariant_load_metadata: builtins.bool = ...,
        xla_llvm_disable_expensive_passes: builtins.bool = ...,
        xla_test_all_output_layouts: builtins.bool = ...,
        xla_test_all_input_layouts: builtins.bool = ...,
        xla_hlo_graph_sharding_color: builtins.bool = ...,
        xla_gpu_use_cudnn_batchnorm: builtins.bool = ...,
        xla_cpu_use_mkl_dnn: builtins.bool = ...,
        xla_gpu_max_kernel_unroll_factor: builtins.int = ...,
        xla_cpu_enable_fast_math: builtins.bool = ...,
        xla_cpu_fast_math_honor_nans: builtins.bool = ...,
        xla_cpu_fast_math_honor_infs: builtins.bool = ...,
        xla_cpu_fast_math_honor_division: builtins.bool = ...,
        xla_cpu_fast_math_honor_functions: builtins.bool = ...,
        xla_cpu_enable_fast_min_max: builtins.bool = ...,
        xla_gpu_enable_fast_min_max: builtins.bool = ...,
        xla_allow_excess_precision: builtins.bool = ...,
        xla_gpu_crash_on_verification_failures: builtins.bool = ...,
        xla_gpu_autotune_level: builtins.int = ...,
        xla_force_host_platform_device_count: builtins.int = ...,
        xla_gpu_disable_gpuasm_optimizations: builtins.bool = ...,
        xla_hlo_evaluator_use_fast_path: builtins.bool = ...,
        xla_allow_scalar_index_dynamic_ops: builtins.bool = ...,
        xla_step_marker_location: global___DebugOptions.StepMarkerLocation.ValueType = ...,
        xla_dump_to: typing.Text = ...,
        xla_dump_hlo_module_re: typing.Text = ...,
        xla_dump_hlo_pass_re: typing.Text = ...,
        xla_dump_hlo_as_text: builtins.bool = ...,
        xla_dump_hlo_as_proto: builtins.bool = ...,
        xla_dump_hlo_as_dot: builtins.bool = ...,
        xla_dump_hlo_as_url: builtins.bool = ...,
        xla_dump_hlo_as_html: builtins.bool = ...,
        xla_dump_fusion_visualization: builtins.bool = ...,
        xla_dump_hlo_snapshots: builtins.bool = ...,
        xla_dump_include_timestamp: builtins.bool = ...,
        xla_dump_max_hlo_modules: builtins.int = ...,
        xla_dump_module_metadata: builtins.bool = ...,
        xla_dump_compress_protos: builtins.bool = ...,
        xla_gpu_force_conv_nchw: builtins.bool = ...,
        xla_gpu_force_conv_nhwc: builtins.bool = ...,
        xla_gpu_ptx_file: typing.Optional[typing.Iterable[typing.Text]] = ...,
        xla_gpu_algorithm_denylist_path: typing.Text = ...,
        xla_gpu_deterministic_reductions: builtins.bool = ...,
        xla_tpu_detect_nan: builtins.bool = ...,
        xla_tpu_detect_inf: builtins.bool = ...,
        xla_cpu_enable_xprof_traceme: builtins.bool = ...,
        xla_gpu_unsafe_fallback_to_driver_on_ptxas_not_found: builtins.bool = ...,
        xla_gpu_asm_extra_flags: typing.Text = ...,
        xla_multiheap_size_constraint_per_heap: builtins.int = ...,
        xla_detailed_logging_and_dumping: builtins.bool = ...,
        xla_gpu_force_compilation_parallelism: builtins.int = ...,
        xla_gpu_deterministic_ops: builtins.bool = ...,
        xla_gpu_llvm_ir_file: typing.Optional[typing.Iterable[typing.Text]] = ...,
        xla_gpu_enable_async_all_reduce: builtins.bool = ...,
        xla_backend_extra_options: typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["xla_allow_excess_precision",b"xla_allow_excess_precision","xla_allow_scalar_index_dynamic_ops",b"xla_allow_scalar_index_dynamic_ops","xla_backend_extra_options",b"xla_backend_extra_options","xla_backend_optimization_level",b"xla_backend_optimization_level","xla_cpu_enable_fast_math",b"xla_cpu_enable_fast_math","xla_cpu_enable_fast_min_max",b"xla_cpu_enable_fast_min_max","xla_cpu_enable_xprof_traceme",b"xla_cpu_enable_xprof_traceme","xla_cpu_fast_math_honor_division",b"xla_cpu_fast_math_honor_division","xla_cpu_fast_math_honor_functions",b"xla_cpu_fast_math_honor_functions","xla_cpu_fast_math_honor_infs",b"xla_cpu_fast_math_honor_infs","xla_cpu_fast_math_honor_nans",b"xla_cpu_fast_math_honor_nans","xla_cpu_multi_thread_eigen",b"xla_cpu_multi_thread_eigen","xla_cpu_use_mkl_dnn",b"xla_cpu_use_mkl_dnn","xla_detailed_logging_and_dumping",b"xla_detailed_logging_and_dumping","xla_disable_all_hlo_passes",b"xla_disable_all_hlo_passes","xla_disable_hlo_passes",b"xla_disable_hlo_passes","xla_dump_compress_protos",b"xla_dump_compress_protos","xla_dump_fusion_visualization",b"xla_dump_fusion_visualization","xla_dump_hlo_as_dot",b"xla_dump_hlo_as_dot","xla_dump_hlo_as_html",b"xla_dump_hlo_as_html","xla_dump_hlo_as_proto",b"xla_dump_hlo_as_proto","xla_dump_hlo_as_text",b"xla_dump_hlo_as_text","xla_dump_hlo_as_url",b"xla_dump_hlo_as_url","xla_dump_hlo_module_re",b"xla_dump_hlo_module_re","xla_dump_hlo_pass_re",b"xla_dump_hlo_pass_re","xla_dump_hlo_snapshots",b"xla_dump_hlo_snapshots","xla_dump_include_timestamp",b"xla_dump_include_timestamp","xla_dump_max_hlo_modules",b"xla_dump_max_hlo_modules","xla_dump_module_metadata",b"xla_dump_module_metadata","xla_dump_to",b"xla_dump_to","xla_eliminate_hlo_implicit_broadcast",b"xla_eliminate_hlo_implicit_broadcast","xla_embed_ir_in_executable",b"xla_embed_ir_in_executable","xla_enable_hlo_passes_only",b"xla_enable_hlo_passes_only","xla_force_host_platform_device_count",b"xla_force_host_platform_device_count","xla_gpu_algorithm_denylist_path",b"xla_gpu_algorithm_denylist_path","xla_gpu_asm_extra_flags",b"xla_gpu_asm_extra_flags","xla_gpu_autotune_level",b"xla_gpu_autotune_level","xla_gpu_crash_on_verification_failures",b"xla_gpu_crash_on_verification_failures","xla_gpu_cuda_data_dir",b"xla_gpu_cuda_data_dir","xla_gpu_deterministic_ops",b"xla_gpu_deterministic_ops","xla_gpu_deterministic_reductions",b"xla_gpu_deterministic_reductions","xla_gpu_disable_gpuasm_optimizations",b"xla_gpu_disable_gpuasm_optimizations","xla_gpu_disable_multi_streaming",b"xla_gpu_disable_multi_streaming","xla_gpu_enable_async_all_reduce",b"xla_gpu_enable_async_all_reduce","xla_gpu_enable_fast_min_max",b"xla_gpu_enable_fast_min_max","xla_gpu_force_compilation_parallelism",b"xla_gpu_force_compilation_parallelism","xla_gpu_force_conv_nchw",b"xla_gpu_force_conv_nchw","xla_gpu_force_conv_nhwc",b"xla_gpu_force_conv_nhwc","xla_gpu_ftz",b"xla_gpu_ftz","xla_gpu_llvm_ir_file",b"xla_gpu_llvm_ir_file","xla_gpu_max_kernel_unroll_factor",b"xla_gpu_max_kernel_unroll_factor","xla_gpu_ptx_file",b"xla_gpu_ptx_file","xla_gpu_unsafe_fallback_to_driver_on_ptxas_not_found",b"xla_gpu_unsafe_fallback_to_driver_on_ptxas_not_found","xla_gpu_use_cudnn_batchnorm",b"xla_gpu_use_cudnn_batchnorm","xla_gpu_use_random_streams",b"xla_gpu_use_random_streams","xla_hlo_evaluator_use_fast_path",b"xla_hlo_evaluator_use_fast_path","xla_hlo_graph_addresses",b"xla_hlo_graph_addresses","xla_hlo_graph_sharding_color",b"xla_hlo_graph_sharding_color","xla_hlo_profile",b"xla_hlo_profile","xla_llvm_disable_expensive_passes",b"xla_llvm_disable_expensive_passes","xla_llvm_enable_alias_scope_metadata",b"xla_llvm_enable_alias_scope_metadata","xla_llvm_enable_invariant_load_metadata",b"xla_llvm_enable_invariant_load_metadata","xla_llvm_enable_noalias_metadata",b"xla_llvm_enable_noalias_metadata","xla_multiheap_size_constraint_per_heap",b"xla_multiheap_size_constraint_per_heap","xla_step_marker_location",b"xla_step_marker_location","xla_test_all_input_layouts",b"xla_test_all_input_layouts","xla_test_all_output_layouts",b"xla_test_all_output_layouts","xla_tpu_detect_inf",b"xla_tpu_detect_inf","xla_tpu_detect_nan",b"xla_tpu_detect_nan"]) -> None: ...
global___DebugOptions = DebugOptions

class ExecutionOptions(google.protobuf.message.Message):
    """These settings control how XLA compiles and/or runs code.  Not all settings
    will have an effect on every platform.

    When adding new fields, keep in mind that boolean fields default to false.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    SHAPE_WITH_OUTPUT_LAYOUT_FIELD_NUMBER: builtins.int
    SEED_FIELD_NUMBER: builtins.int
    DEBUG_OPTIONS_FIELD_NUMBER: builtins.int
    DEVICE_HANDLES_FIELD_NUMBER: builtins.int
    NUM_REPLICAS_FIELD_NUMBER: builtins.int
    DEVICE_ASSIGNMENT_FIELD_NUMBER: builtins.int
    ALIAS_PASSTHROUGH_PARAMS_FIELD_NUMBER: builtins.int
    NUM_PARTITIONS_FIELD_NUMBER: builtins.int
    LAUNCH_ID_FIELD_NUMBER: builtins.int
    USE_SPMD_PARTITIONING_FIELD_NUMBER: builtins.int
    DEDUPLICATE_HLO_FIELD_NUMBER: builtins.int
    @property
    def shape_with_output_layout(self) -> tensorflow.compiler.xla.xla_data_pb2.ShapeProto:
        """This optional field's layout is used as a hint when storing the output of
        this computation.  Subsequent transfers of this output array to the client
        may be faster when using this layout.

        We use a Shape here to accommodate computations that return a tuple.
        """
        pass
    seed: builtins.int
    """Used to seed random-number generators used in this computation.  If this is
    0, we generate a seed ourselves.

    TODO(b/32083678): Changing the seed unnecessarily forces a recompilation.
    """

    @property
    def debug_options(self) -> global___DebugOptions: ...
    @property
    def device_handles(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[tensorflow.compiler.xla.xla_data_pb2.DeviceHandle]:
        """This optional field specifies a particular set of devices to run the
        computation on. The computation will be partitioned across these devices.
        If not provided, the default device will be chosen.
        """
        pass
    num_replicas: builtins.int
    """Number of replicas of the computation to run. If zero, uses the default
    number of replicas for the XLA service.
    """

    @property
    def device_assignment(self) -> tensorflow.compiler.xla.xla_data_pb2.DeviceAssignmentProto:
        """This optional field specifies the device assignment if known at compile
        time.
        """
        pass
    alias_passthrough_params: builtins.bool
    """Alias input and output buffers for parameters that are passed-through XLA
    modules without being changed.
    """

    num_partitions: builtins.int
    """Number of partitions of the computation to run (model parallelism).
    If zero, uses the default number of partitions for the XLA service.
    """

    launch_id: builtins.int
    """Used to identify a set of programs that should be launch together."""

    use_spmd_partitioning: builtins.bool
    """Indicates whether to use SPMD (true) or MPMD (false) partitioning when
    num_partitions > 1 and XLA is requested to partition the input program.
    """

    deduplicate_hlo: builtins.bool
    """If set, deduplicate hlo into function calls to reduce binary size. Only
    works on TPU.
    """

    def __init__(self,
        *,
        shape_with_output_layout: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ShapeProto] = ...,
        seed: builtins.int = ...,
        debug_options: typing.Optional[global___DebugOptions] = ...,
        device_handles: typing.Optional[typing.Iterable[tensorflow.compiler.xla.xla_data_pb2.DeviceHandle]] = ...,
        num_replicas: builtins.int = ...,
        device_assignment: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.DeviceAssignmentProto] = ...,
        alias_passthrough_params: builtins.bool = ...,
        num_partitions: builtins.int = ...,
        launch_id: builtins.int = ...,
        use_spmd_partitioning: builtins.bool = ...,
        deduplicate_hlo: builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["debug_options",b"debug_options","device_assignment",b"device_assignment","shape_with_output_layout",b"shape_with_output_layout"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["alias_passthrough_params",b"alias_passthrough_params","debug_options",b"debug_options","deduplicate_hlo",b"deduplicate_hlo","device_assignment",b"device_assignment","device_handles",b"device_handles","launch_id",b"launch_id","num_partitions",b"num_partitions","num_replicas",b"num_replicas","seed",b"seed","shape_with_output_layout",b"shape_with_output_layout","use_spmd_partitioning",b"use_spmd_partitioning"]) -> None: ...
global___ExecutionOptions = ExecutionOptions

class GetDeviceHandlesRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DEVICE_COUNT_FIELD_NUMBER: builtins.int
    device_count: builtins.int
    def __init__(self,
        *,
        device_count: builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["device_count",b"device_count"]) -> None: ...
global___GetDeviceHandlesRequest = GetDeviceHandlesRequest

class GetDeviceHandlesResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DEVICE_HANDLES_FIELD_NUMBER: builtins.int
    @property
    def device_handles(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[tensorflow.compiler.xla.xla_data_pb2.DeviceHandle]: ...
    def __init__(self,
        *,
        device_handles: typing.Optional[typing.Iterable[tensorflow.compiler.xla.xla_data_pb2.DeviceHandle]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["device_handles",b"device_handles"]) -> None: ...
global___GetDeviceHandlesResponse = GetDeviceHandlesResponse

class TransferToClientRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DATA_FIELD_NUMBER: builtins.int
    SHAPE_WITH_LAYOUT_FIELD_NUMBER: builtins.int
    @property
    def data(self) -> tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle: ...
    @property
    def shape_with_layout(self) -> tensorflow.compiler.xla.xla_data_pb2.ShapeProto:
        """This optional field directs the service to return the literal in this
        layout. A shape is used to hold the layout to accommodate tuples.
        """
        pass
    def __init__(self,
        *,
        data: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle] = ...,
        shape_with_layout: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ShapeProto] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["data",b"data","shape_with_layout",b"shape_with_layout"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["data",b"data","shape_with_layout",b"shape_with_layout"]) -> None: ...
global___TransferToClientRequest = TransferToClientRequest

class TransferToClientResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    LITERAL_FIELD_NUMBER: builtins.int
    @property
    def literal(self) -> tensorflow.compiler.xla.xla_data_pb2.LiteralProto: ...
    def __init__(self,
        *,
        literal: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.LiteralProto] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["literal",b"literal"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["literal",b"literal"]) -> None: ...
global___TransferToClientResponse = TransferToClientResponse

class TransferToServerRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    LITERAL_FIELD_NUMBER: builtins.int
    DEVICE_HANDLE_FIELD_NUMBER: builtins.int
    @property
    def literal(self) -> tensorflow.compiler.xla.xla_data_pb2.LiteralProto: ...
    @property
    def device_handle(self) -> tensorflow.compiler.xla.xla_data_pb2.DeviceHandle: ...
    def __init__(self,
        *,
        literal: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.LiteralProto] = ...,
        device_handle: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.DeviceHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["device_handle",b"device_handle","literal",b"literal"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["device_handle",b"device_handle","literal",b"literal"]) -> None: ...
global___TransferToServerRequest = TransferToServerRequest

class TransferToServerResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DATA_FIELD_NUMBER: builtins.int
    @property
    def data(self) -> tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle: ...
    def __init__(self,
        *,
        data: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["data",b"data"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["data",b"data"]) -> None: ...
global___TransferToServerResponse = TransferToServerResponse

class TransferToInfeedRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    LITERAL_FIELD_NUMBER: builtins.int
    REPLICA_ID_FIELD_NUMBER: builtins.int
    DEVICE_HANDLE_FIELD_NUMBER: builtins.int
    @property
    def literal(self) -> tensorflow.compiler.xla.xla_data_pb2.LiteralProto: ...
    replica_id: builtins.int
    @property
    def device_handle(self) -> tensorflow.compiler.xla.xla_data_pb2.DeviceHandle: ...
    def __init__(self,
        *,
        literal: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.LiteralProto] = ...,
        replica_id: builtins.int = ...,
        device_handle: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.DeviceHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["device_handle",b"device_handle","literal",b"literal"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["device_handle",b"device_handle","literal",b"literal","replica_id",b"replica_id"]) -> None: ...
global___TransferToInfeedRequest = TransferToInfeedRequest

class TransferToInfeedResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    def __init__(self,
        ) -> None: ...
global___TransferToInfeedResponse = TransferToInfeedResponse

class TransferFromOutfeedRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    SHAPE_WITH_LAYOUT_FIELD_NUMBER: builtins.int
    REPLICA_ID_FIELD_NUMBER: builtins.int
    DEVICE_HANDLE_FIELD_NUMBER: builtins.int
    @property
    def shape_with_layout(self) -> tensorflow.compiler.xla.xla_data_pb2.ShapeProto:
        """This optional field directs the service to return the literal in this
        layout. A shape is used to hold the layout to accommodate tuples.
        """
        pass
    replica_id: builtins.int
    @property
    def device_handle(self) -> tensorflow.compiler.xla.xla_data_pb2.DeviceHandle: ...
    def __init__(self,
        *,
        shape_with_layout: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ShapeProto] = ...,
        replica_id: builtins.int = ...,
        device_handle: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.DeviceHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["device_handle",b"device_handle","shape_with_layout",b"shape_with_layout"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["device_handle",b"device_handle","replica_id",b"replica_id","shape_with_layout",b"shape_with_layout"]) -> None: ...
global___TransferFromOutfeedRequest = TransferFromOutfeedRequest

class TransferFromOutfeedResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    LITERAL_FIELD_NUMBER: builtins.int
    @property
    def literal(self) -> tensorflow.compiler.xla.xla_data_pb2.LiteralProto: ...
    def __init__(self,
        *,
        literal: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.LiteralProto] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["literal",b"literal"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["literal",b"literal"]) -> None: ...
global___TransferFromOutfeedResponse = TransferFromOutfeedResponse

class ResetDeviceRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DEVICE_HANDLE_FIELD_NUMBER: builtins.int
    @property
    def device_handle(self) -> tensorflow.compiler.xla.xla_data_pb2.DeviceHandle: ...
    def __init__(self,
        *,
        device_handle: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.DeviceHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["device_handle",b"device_handle"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["device_handle",b"device_handle"]) -> None: ...
global___ResetDeviceRequest = ResetDeviceRequest

class ResetDeviceResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    def __init__(self,
        ) -> None: ...
global___ResetDeviceResponse = ResetDeviceResponse

class ComputationGraphStatsRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    COMPUTATION_FIELD_NUMBER: builtins.int
    DEBUG_OPTIONS_FIELD_NUMBER: builtins.int
    @property
    def computation(self) -> tensorflow.compiler.xla.service.hlo_pb2.HloModuleProto: ...
    @property
    def debug_options(self) -> global___DebugOptions: ...
    def __init__(self,
        *,
        computation: typing.Optional[tensorflow.compiler.xla.service.hlo_pb2.HloModuleProto] = ...,
        debug_options: typing.Optional[global___DebugOptions] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["computation",b"computation","debug_options",b"debug_options"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["computation",b"computation","debug_options",b"debug_options"]) -> None: ...
global___ComputationGraphStatsRequest = ComputationGraphStatsRequest

class ComputationStatsResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    STATS_FIELD_NUMBER: builtins.int
    @property
    def stats(self) -> tensorflow.compiler.xla.xla_data_pb2.ComputationStats: ...
    def __init__(self,
        *,
        stats: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ComputationStats] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["stats",b"stats"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["stats",b"stats"]) -> None: ...
global___ComputationStatsResponse = ComputationStatsResponse

class CreateChannelHandleRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    CHANNEL_TYPE_FIELD_NUMBER: builtins.int
    channel_type: tensorflow.compiler.xla.xla_data_pb2.ChannelHandle.ChannelType.ValueType
    def __init__(self,
        *,
        channel_type: tensorflow.compiler.xla.xla_data_pb2.ChannelHandle.ChannelType.ValueType = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["channel_type",b"channel_type"]) -> None: ...
global___CreateChannelHandleRequest = CreateChannelHandleRequest

class CreateChannelHandleResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    CHANNEL_FIELD_NUMBER: builtins.int
    @property
    def channel(self) -> tensorflow.compiler.xla.xla_data_pb2.ChannelHandle: ...
    def __init__(self,
        *,
        channel: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ChannelHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["channel",b"channel"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["channel",b"channel"]) -> None: ...
global___CreateChannelHandleResponse = CreateChannelHandleResponse

class UnregisterRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DATA_FIELD_NUMBER: builtins.int
    @property
    def data(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle]: ...
    def __init__(self,
        *,
        data: typing.Optional[typing.Iterable[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["data",b"data"]) -> None: ...
global___UnregisterRequest = UnregisterRequest

class UnregisterResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    def __init__(self,
        ) -> None: ...
global___UnregisterResponse = UnregisterResponse

class CompileRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    COMPUTATION_FIELD_NUMBER: builtins.int
    EXECUTION_OPTIONS_FIELD_NUMBER: builtins.int
    INPUT_SHAPE_WITH_LAYOUT_FIELD_NUMBER: builtins.int
    @property
    def computation(self) -> tensorflow.compiler.xla.service.hlo_pb2.HloModuleProto:
        """The graph to be compiled."""
        pass
    @property
    def execution_options(self) -> global___ExecutionOptions:
        """Options that affect how XLA compiles code to service this request."""
        pass
    @property
    def input_shape_with_layout(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[tensorflow.compiler.xla.xla_data_pb2.ShapeProto]:
        """The layouts of the input arguments. If not set, the default layout will be
        used. Although the real arguments are not needed in compilation, the
        layouts of the arguments can affect the compilation.
        """
        pass
    def __init__(self,
        *,
        computation: typing.Optional[tensorflow.compiler.xla.service.hlo_pb2.HloModuleProto] = ...,
        execution_options: typing.Optional[global___ExecutionOptions] = ...,
        input_shape_with_layout: typing.Optional[typing.Iterable[tensorflow.compiler.xla.xla_data_pb2.ShapeProto]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["computation",b"computation","execution_options",b"execution_options"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["computation",b"computation","execution_options",b"execution_options","input_shape_with_layout",b"input_shape_with_layout"]) -> None: ...
global___CompileRequest = CompileRequest

class CompileResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    HANDLE_FIELD_NUMBER: builtins.int
    @property
    def handle(self) -> tensorflow.compiler.xla.xla_data_pb2.ExecutionHandle:
        """The handle to the executable."""
        pass
    def __init__(self,
        *,
        handle: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ExecutionHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["handle",b"handle"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["handle",b"handle"]) -> None: ...
global___CompileResponse = CompileResponse

class ExecuteRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    HANDLE_FIELD_NUMBER: builtins.int
    ARGUMENTS_FIELD_NUMBER: builtins.int
    @property
    def handle(self) -> tensorflow.compiler.xla.xla_data_pb2.ExecutionHandle: ...
    @property
    def arguments(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle]:
        """The shape and layout of the arguments must be the same as the those of the
        executable's parameters.
        """
        pass
    def __init__(self,
        *,
        handle: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ExecutionHandle] = ...,
        arguments: typing.Optional[typing.Iterable[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["handle",b"handle"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["arguments",b"arguments","handle",b"handle"]) -> None: ...
global___ExecuteRequest = ExecuteRequest

class ExecuteGraphRequest(google.protobuf.message.Message):
    """TODO(b/118493728): Remove this and ExecuteGraphParallelRequest and replace
    the uses with calls to Compile and Execute.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    COMPUTATION_FIELD_NUMBER: builtins.int
    ARGUMENTS_FIELD_NUMBER: builtins.int
    EXECUTION_OPTIONS_FIELD_NUMBER: builtins.int
    @property
    def computation(self) -> tensorflow.compiler.xla.service.hlo_pb2.HloModuleProto: ...
    @property
    def arguments(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle]: ...
    @property
    def execution_options(self) -> global___ExecutionOptions:
        """Options that affect how XLA compiles and runs code to service this request."""
        pass
    def __init__(self,
        *,
        computation: typing.Optional[tensorflow.compiler.xla.service.hlo_pb2.HloModuleProto] = ...,
        arguments: typing.Optional[typing.Iterable[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle]] = ...,
        execution_options: typing.Optional[global___ExecutionOptions] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["computation",b"computation","execution_options",b"execution_options"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["arguments",b"arguments","computation",b"computation","execution_options",b"execution_options"]) -> None: ...
global___ExecuteGraphRequest = ExecuteGraphRequest

class ExecuteGraphParallelRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    REQUESTS_FIELD_NUMBER: builtins.int
    @property
    def requests(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ExecuteGraphRequest]: ...
    def __init__(self,
        *,
        requests: typing.Optional[typing.Iterable[global___ExecuteGraphRequest]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["requests",b"requests"]) -> None: ...
global___ExecuteGraphParallelRequest = ExecuteGraphParallelRequest

class ExecuteResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    OUTPUT_FIELD_NUMBER: builtins.int
    PROFILE_FIELD_NUMBER: builtins.int
    @property
    def output(self) -> tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle: ...
    @property
    def profile(self) -> tensorflow.compiler.xla.xla_data_pb2.ExecutionProfile: ...
    def __init__(self,
        *,
        output: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle] = ...,
        profile: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ExecutionProfile] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["output",b"output","profile",b"profile"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["output",b"output","profile",b"profile"]) -> None: ...
global___ExecuteResponse = ExecuteResponse

class ExecuteParallelResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    RESPONSES_FIELD_NUMBER: builtins.int
    @property
    def responses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ExecuteResponse]: ...
    def __init__(self,
        *,
        responses: typing.Optional[typing.Iterable[global___ExecuteResponse]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["responses",b"responses"]) -> None: ...
global___ExecuteParallelResponse = ExecuteParallelResponse

class WaitForExecutionRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    EXECUTION_FIELD_NUMBER: builtins.int
    @property
    def execution(self) -> tensorflow.compiler.xla.xla_data_pb2.ExecutionHandle: ...
    def __init__(self,
        *,
        execution: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ExecutionHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["execution",b"execution"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["execution",b"execution"]) -> None: ...
global___WaitForExecutionRequest = WaitForExecutionRequest

class WaitForExecutionResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    OUTPUT_FIELD_NUMBER: builtins.int
    PROFILE_FIELD_NUMBER: builtins.int
    @property
    def output(self) -> tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle: ...
    @property
    def profile(self) -> tensorflow.compiler.xla.xla_data_pb2.ExecutionProfile: ...
    def __init__(self,
        *,
        output: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle] = ...,
        profile: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ExecutionProfile] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["output",b"output","profile",b"profile"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["output",b"output","profile",b"profile"]) -> None: ...
global___WaitForExecutionResponse = WaitForExecutionResponse

class ComputeConstantGraphRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    COMPUTATION_FIELD_NUMBER: builtins.int
    OUTPUT_LAYOUT_FIELD_NUMBER: builtins.int
    @property
    def computation(self) -> tensorflow.compiler.xla.service.hlo_pb2.HloModuleProto: ...
    @property
    def output_layout(self) -> tensorflow.compiler.xla.xla_data_pb2.LayoutProto: ...
    def __init__(self,
        *,
        computation: typing.Optional[tensorflow.compiler.xla.service.hlo_pb2.HloModuleProto] = ...,
        output_layout: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.LayoutProto] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["computation",b"computation","output_layout",b"output_layout"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["computation",b"computation","output_layout",b"output_layout"]) -> None: ...
global___ComputeConstantGraphRequest = ComputeConstantGraphRequest

class ComputeConstantResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    LITERAL_FIELD_NUMBER: builtins.int
    @property
    def literal(self) -> tensorflow.compiler.xla.xla_data_pb2.LiteralProto:
        """A LiteralProto is returned directly for this request."""
        pass
    def __init__(self,
        *,
        literal: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.LiteralProto] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["literal",b"literal"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["literal",b"literal"]) -> None: ...
global___ComputeConstantResponse = ComputeConstantResponse

class DeconstructTupleRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    TUPLE_HANDLE_FIELD_NUMBER: builtins.int
    @property
    def tuple_handle(self) -> tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle: ...
    def __init__(self,
        *,
        tuple_handle: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["tuple_handle",b"tuple_handle"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["tuple_handle",b"tuple_handle"]) -> None: ...
global___DeconstructTupleRequest = DeconstructTupleRequest

class DeconstructTupleResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ELEMENT_HANDLES_FIELD_NUMBER: builtins.int
    @property
    def element_handles(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle]: ...
    def __init__(self,
        *,
        element_handles: typing.Optional[typing.Iterable[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["element_handles",b"element_handles"]) -> None: ...
global___DeconstructTupleResponse = DeconstructTupleResponse

class LoadDataRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    COLUMNIO_TABLET_PATH_FIELD_NUMBER: builtins.int
    COLUMNIO_FIELD_FIELD_NUMBER: builtins.int
    ELEMENT_SHAPE_FIELD_NUMBER: builtins.int
    OFFSET_FIELD_NUMBER: builtins.int
    LIMIT_FIELD_NUMBER: builtins.int
    ZIP_FIELD_NUMBER: builtins.int
    columnio_tablet_path: typing.Text
    """Describes the path of the ColumnIO tablet to load."""

    columnio_field: typing.Text
    """Describes the field to load within the ColumnIO tablet."""

    @property
    def element_shape(self) -> tensorflow.compiler.xla.xla_data_pb2.ShapeProto:
        """Individual element shape, excluding rows."""
        pass
    offset: builtins.int
    """Warning: ColumnIO does not support random-access, so use offset with
    caution in performance-critical scenarios.
    """

    limit: builtins.int
    """Maximum number of elements (with shape element_shape) to load."""

    zip: builtins.bool
    """If more than one item is requested (via limit > 1), then this request
    attribute zips together the produced vectors.
    """

    def __init__(self,
        *,
        columnio_tablet_path: typing.Text = ...,
        columnio_field: typing.Text = ...,
        element_shape: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ShapeProto] = ...,
        offset: builtins.int = ...,
        limit: builtins.int = ...,
        zip: builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["element_shape",b"element_shape"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["columnio_field",b"columnio_field","columnio_tablet_path",b"columnio_tablet_path","element_shape",b"element_shape","limit",b"limit","offset",b"offset","zip",b"zip"]) -> None: ...
global___LoadDataRequest = LoadDataRequest

class LoadDataResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DATA_FIELD_NUMBER: builtins.int
    DATA_SHAPE_FIELD_NUMBER: builtins.int
    AVAILABLE_ROWS_FIELD_NUMBER: builtins.int
    ROWS_LOADED_FIELD_NUMBER: builtins.int
    NANOSECONDS_FIELD_NUMBER: builtins.int
    @property
    def data(self) -> tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle: ...
    @property
    def data_shape(self) -> tensorflow.compiler.xla.xla_data_pb2.ShapeProto: ...
    available_rows: builtins.int
    rows_loaded: builtins.int
    nanoseconds: builtins.int
    def __init__(self,
        *,
        data: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle] = ...,
        data_shape: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ShapeProto] = ...,
        available_rows: builtins.int = ...,
        rows_loaded: builtins.int = ...,
        nanoseconds: builtins.int = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["data",b"data","data_shape",b"data_shape"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["available_rows",b"available_rows","data",b"data","data_shape",b"data_shape","nanoseconds",b"nanoseconds","rows_loaded",b"rows_loaded"]) -> None: ...
global___LoadDataResponse = LoadDataResponse

class GetShapeRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DATA_FIELD_NUMBER: builtins.int
    @property
    def data(self) -> tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle: ...
    def __init__(self,
        *,
        data: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["data",b"data"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["data",b"data"]) -> None: ...
global___GetShapeRequest = GetShapeRequest

class GetShapeResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    SHAPE_FIELD_NUMBER: builtins.int
    @property
    def shape(self) -> tensorflow.compiler.xla.xla_data_pb2.ShapeProto: ...
    def __init__(self,
        *,
        shape: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.ShapeProto] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["shape",b"shape"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["shape",b"shape"]) -> None: ...
global___GetShapeResponse = GetShapeResponse

class UnpackRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DATA_FIELD_NUMBER: builtins.int
    @property
    def data(self) -> tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle: ...
    def __init__(self,
        *,
        data: typing.Optional[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["data",b"data"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["data",b"data"]) -> None: ...
global___UnpackRequest = UnpackRequest

class UnpackResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    TIED_DATA_FIELD_NUMBER: builtins.int
    @property
    def tied_data(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle]: ...
    def __init__(self,
        *,
        tied_data: typing.Optional[typing.Iterable[tensorflow.compiler.xla.xla_data_pb2.GlobalDataHandle]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["tied_data",b"tied_data"]) -> None: ...
global___UnpackResponse = UnpackResponse
