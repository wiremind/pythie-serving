# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow/compiler/xla/rpc/xla_service.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import builder as _builder
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from pythie_serving.tensorflow_proto.tensorflow.compiler.xla import xla_pb2 as tensorflow_dot_compiler_dot_xla_dot_xla__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n-tensorflow/compiler/xla/rpc/xla_service.proto\x12\x03xla\x1a!tensorflow/compiler/xla/xla.proto2\xea\n\n\nXlaService\x12?\n\nUnregister\x12\x16.xla.UnregisterRequest\x1a\x17.xla.UnregisterResponse\"\x00\x12Q\n\x10\x44\x65\x63onstructTuple\x12\x1c.xla.DeconstructTupleRequest\x1a\x1d.xla.DeconstructTupleResponse\"\x00\x12\x33\n\x06Unpack\x12\x12.xla.UnpackRequest\x1a\x13.xla.UnpackResponse\"\x00\x12\x39\n\x08GetShape\x12\x14.xla.GetShapeRequest\x1a\x15.xla.GetShapeResponse\"\x00\x12^\n\x18GetComputationGraphStats\x12!.xla.ComputationGraphStatsRequest\x1a\x1d.xla.ComputationStatsResponse\"\x00\x12\x39\n\x08LoadData\x12\x14.xla.LoadDataRequest\x1a\x15.xla.LoadDataResponse\"\x00\x12Q\n\x10TransferToClient\x12\x1c.xla.TransferToClientRequest\x1a\x1d.xla.TransferToClientResponse\"\x00\x12Q\n\x10TransferToServer\x12\x1c.xla.TransferToServerRequest\x1a\x1d.xla.TransferToServerResponse\"\x00\x12Q\n\x10TransferToInfeed\x12\x1c.xla.TransferToInfeedRequest\x1a\x1d.xla.TransferToInfeedResponse\"\x00\x12Z\n\x13TransferFromOutfeed\x12\x1f.xla.TransferFromOutfeedRequest\x1a .xla.TransferFromOutfeedResponse\"\x00\x12\x42\n\x0bResetDevice\x12\x17.xla.ResetDeviceRequest\x1a\x18.xla.ResetDeviceResponse\"\x00\x12X\n\x14\x43omputeConstantGraph\x12 .xla.ComputeConstantGraphRequest\x1a\x1c.xla.ComputeConstantResponse\"\x00\x12Q\n\x10GetDeviceHandles\x12\x1c.xla.GetDeviceHandlesRequest\x1a\x1d.xla.GetDeviceHandlesResponse\"\x00\x12Z\n\x13\x43reateChannelHandle\x12\x1f.xla.CreateChannelHandleRequest\x1a .xla.CreateChannelHandleResponse\"\x00\x12\x36\n\x07\x43ompile\x12\x13.xla.CompileRequest\x1a\x14.xla.CompileResponse\"\x00\x12\x36\n\x07\x45xecute\x12\x13.xla.ExecuteRequest\x1a\x14.xla.ExecuteResponse\"\x00\x12X\n\x14\x45xecuteGraphParallel\x12 .xla.ExecuteGraphParallelRequest\x1a\x1c.xla.ExecuteParallelResponse\"\x00\x12Q\n\x10WaitForExecution\x12\x1c.xla.WaitForExecutionRequest\x1a\x1d.xla.WaitForExecutionResponse\"\x00\x62\x06proto3')

_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'tensorflow.compiler.xla.rpc.xla_service_pb2', globals())
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  _XLASERVICE._serialized_start=90
  _XLASERVICE._serialized_end=1476
# @@protoc_insertion_point(module_scope)
